{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Index<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Time-Forest\" data-toc-modified-id=\"Time-Forest-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Time Forest</a></span></li><li><span><a href=\"#Optimize-Random-Forest-and-lgbm-benchmarks\" data-toc-modified-id=\"Optimize-Random-Forest-and-lgbm-benchmarks-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Optimize Random Forest and lgbm benchmarks</a></span><ul class=\"toc-item\"><li><span><a href=\"#Tuned-RF\" data-toc-modified-id=\"Tuned-RF-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Tuned RF</a></span></li><li><span><a href=\"#lgbm\" data-toc-modified-id=\"lgbm-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>lgbm</a></span></li></ul></li><li><span><a href=\"#Out-of-time\" data-toc-modified-id=\"Out-of-time-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Out of time</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GE News - Time Forest Vs Sklearn's Random Forest and LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T18:23:25.153338Z",
     "start_time": "2021-08-18T18:23:23.473432Z"
    },
    "execution": {
     "iopub.execute_input": "2021-08-22T04:02:07.672861Z",
     "iopub.status.busy": "2021-08-22T04:02:07.672611Z",
     "iopub.status.idle": "2021-08-22T04:02:08.804602Z",
     "shell.execute_reply": "2021-08-22T04:02:08.804043Z",
     "shell.execute_reply.started": "2021-08-22T04:02:07.672831Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.conda/envs/msc/lib/python3.6/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.feature_extraction.stop_words module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction.text. Anything that cannot be imported from sklearn.feature_extraction.text is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import metrics\n",
    "from time import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from time_robust_forest.models import TimeForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import log_loss, f1_score, accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from models.aux_functions import *\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T18:23:25.158648Z",
     "start_time": "2021-08-18T18:23:25.155627Z"
    },
    "execution": {
     "iopub.execute_input": "2021-08-22T04:02:08.805831Z",
     "iopub.status.busy": "2021-08-22T04:02:08.805653Z",
     "iopub.status.idle": "2021-08-22T04:02:08.808794Z",
     "shell.execute_reply": "2021-08-22T04:02:08.808298Z",
     "shell.execute_reply.started": "2021-08-22T04:02:08.805809Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_style():\n",
    "    plt.style.use(['seaborn-white', 'seaborn-paper'])\n",
    "    plt.rcParams['figure.figsize'] = (12, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T18:23:25.169921Z",
     "start_time": "2021-08-18T18:23:25.166281Z"
    },
    "execution": {
     "iopub.execute_input": "2021-08-22T04:02:08.810094Z",
     "iopub.status.busy": "2021-08-22T04:02:08.809927Z",
     "iopub.status.idle": "2021-08-22T04:02:08.814581Z",
     "shell.execute_reply": "2021-08-22T04:02:08.814097Z",
     "shell.execute_reply.started": "2021-08-22T04:02:08.810073Z"
    }
   },
   "outputs": [],
   "source": [
    "set_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T18:23:25.184906Z",
     "start_time": "2021-08-18T18:23:25.172647Z"
    },
    "execution": {
     "iopub.execute_input": "2021-08-22T04:02:08.815706Z",
     "iopub.status.busy": "2021-08-22T04:02:08.815539Z",
     "iopub.status.idle": "2021-08-22T04:02:08.826479Z",
     "shell.execute_reply": "2021-08-22T04:02:08.826016Z",
     "shell.execute_reply.started": "2021-08-22T04:02:08.815685Z"
    }
   },
   "outputs": [],
   "source": [
    "STOP_WORDS = ['de', 'a', 'o', 'que', 'e', 'do', 'da', 'em', 'um', 'para', 'é', 'com', 'não', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'foi', 'ao', 'ele', 'das', 'tem', 'à', 'seu', 'sua', 'ou', 'ser', 'quando', 'muito', 'há', 'nos', 'já', 'está', 'eu', 'também', 'só', 'pelo', 'pela', 'até', 'isso', 'ela', 'entre', 'era', 'depois', 'sem', 'mesmo', 'aos', 'ter', 'seus', 'quem', 'nas', 'me', 'esse', 'eles', 'estão', 'você', 'tinha', 'foram', 'essa', 'num', 'nem', 'suas', 'meu', 'às', 'minha', 'têm', 'numa', 'pelos', 'elas', 'havia', 'seja', 'qual', 'será', 'nós', 'tenho', 'lhe', 'deles', 'essas', 'esses', 'pelas', 'este', 'fosse', 'dele', 'tu', 'te', 'vocês', 'vos', 'lhes', 'meus', 'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso', 'nossa', 'nossos', 'nossas', 'dela', 'delas', 'esta', 'estes', 'estas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'isto', 'aquilo', 'estou', 'está', 'estamos', 'estão', 'estive', 'esteve', 'estivemos', 'estiveram', 'estava', 'estávamos', 'estavam', 'estivera', 'estivéramos', 'esteja', 'estejamos', 'estejam', 'estivesse', 'estivéssemos', 'estivessem', 'estiver', 'estivermos', 'estiverem', 'hei', 'há', 'havemos', 'hão', 'houve', 'houvemos', 'houveram', 'houvera', 'houvéramos', 'haja', 'hajamos', 'hajam', 'houvesse', 'houvéssemos', 'houvessem', 'houver', 'houvermos', 'houverem', 'houverei', 'houverá', 'houveremos', 'houverão', 'houveria', 'houveríamos', 'houveriam', 'sou', 'somos', 'são', 'era', 'éramos', 'eram', 'fui', 'foi', 'fomos', 'foram', 'fora', 'fôramos', 'seja', 'sejamos', 'sejam', 'fosse', 'fôssemos', 'fossem', 'for', 'formos', 'forem', 'serei', 'será', 'seremos', 'serão', 'seria', 'seríamos', 'seriam', 'tenho', 'tem', 'temos', 'tém', 'tinha', 'tínhamos', 'tinham', 'tive', 'teve', 'tivemos', 'tiveram', 'tivera', 'tivéramos', 'tenha', 'tenhamos', 'tenham', 'tivesse', 'tivéssemos', 'tivessem', 'tiver', 'tivermos', 'tiverem', 'terei', 'terá', 'teremos', 'terão', 'teria', 'teríamos', 'teriam']\n",
    "CLUB_WORDS = [\"verdão\", \"tricolor\", \"fla\", \"timão\", \"rubro\", \n",
    "              \"negro\", \"flamengo\", \"paulo\", \"palmeirense\", \"paulista\", \n",
    "              \"inter\", \"colorado\", \"internacional\", \"colorados\", \"colorada\"]\n",
    "STOP_WORDS += CLUB_WORDS\n",
    "MAX_VOCABULARY = 300\n",
    "positive_case = \"flamengo\"\n",
    "PREFIX = \"ge_tfidf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T18:23:28.205861Z",
     "start_time": "2021-08-18T18:23:25.187306Z"
    },
    "execution": {
     "iopub.execute_input": "2021-08-22T04:02:08.827303Z",
     "iopub.status.busy": "2021-08-22T04:02:08.827144Z",
     "iopub.status.idle": "2021-08-22T04:02:12.011419Z",
     "shell.execute_reply": "2021-08-22T04:02:12.010810Z",
     "shell.execute_reply.started": "2021-08-22T04:02:08.827282Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"~/Documents/datasets/ge_news/data/ge_news.csv\", index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T18:23:28.212965Z",
     "start_time": "2021-08-18T18:23:28.207814Z"
    },
    "execution": {
     "iopub.execute_input": "2021-08-22T04:02:12.012533Z",
     "iopub.status.busy": "2021-08-22T04:02:12.012340Z",
     "iopub.status.idle": "2021-08-22T04:02:12.017336Z",
     "shell.execute_reply": "2021-08-22T04:02:12.016868Z",
     "shell.execute_reply.started": "2021-08-22T04:02:12.012510Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139934, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T18:23:28.226150Z",
     "start_time": "2021-08-18T18:23:28.215321Z"
    },
    "execution": {
     "iopub.execute_input": "2021-08-22T04:02:12.018313Z",
     "iopub.status.busy": "2021-08-22T04:02:12.018145Z",
     "iopub.status.idle": "2021-08-22T04:02:12.027242Z",
     "shell.execute_reply": "2021-08-22T04:02:12.026775Z",
     "shell.execute_reply.started": "2021-08-22T04:02:12.018292Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_different_time_slices(data, time_col=\"date\", aggregation=\"weekly\", n_months=None):\n",
    "    if aggregation == \"daily\": return data[time_col].dt.date\n",
    "    if aggregation == \"weekly\": return data[time_col].dt.week\n",
    "    if aggregation == \"monthly\": return data[time_col].apply(lambda x: x.strftime(\"%Y-%m\"))\n",
    "    if aggregation == \"semester\": return False\n",
    "\n",
    "\n",
    "def exclude_periods_without_positive_case(data, positive_case, period_column, threshold=20):\n",
    "    df = data.groupby(period_column)[\"club\"].apply(lambda x: np.sum(x == positive_case))\n",
    "    df = df[df > threshold]\n",
    "    return data[data[period_column].isin(df.index)]\n",
    "    \n",
    "def clean_club_name_from_article(data):\n",
    "    data[\"text\"] = data.apply(lambda x: x[\"text\"].lower().replace(x[\"club\"].replace(\"-\", \" \"), \"\"), axis=1)\n",
    "    return data\n",
    "\n",
    "def exclude_numbers(data):\n",
    "    data[\"text\"] = data[\"text\"].apply(lambda x: ''.join([i for i in x.lower() if not i.isdigit()]))\n",
    "    return data\n",
    "\n",
    "def drop_multiple_teams_news(data):\n",
    "    multiple_team_news = data.groupby(\"link\", as_index=False)[\"club\"].count()\n",
    "    multiple_team_news = multiple_team_news[multiple_team_news[\"club\"] > 1][\"link\"]\n",
    "    return data[~data[\"link\"].isin(multiple_team_news)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T18:23:54.030993Z",
     "start_time": "2021-08-18T18:23:28.233337Z"
    },
    "execution": {
     "iopub.execute_input": "2021-08-22T04:02:12.028107Z",
     "iopub.status.busy": "2021-08-22T04:02:12.027947Z"
    }
   },
   "outputs": [],
   "source": [
    "data = clean_club_name_from_article(data)\n",
    "data = exclude_numbers(data)\n",
    "data = drop_multiple_teams_news(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T18:23:54.149946Z",
     "start_time": "2021-08-18T18:23:54.035308Z"
    }
   },
   "outputs": [],
   "source": [
    "#data = data.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T18:23:54.216298Z",
     "start_time": "2021-08-18T18:23:54.152025Z"
    }
   },
   "outputs": [],
   "source": [
    "data.loc[:, \"year\"] = data[\"date\"].apply(lambda x: x.split(\"/\")[-1])\n",
    "data.loc[:, \"month\"] = data[\"date\"].apply(lambda x: x.split(\"/\")[1])\n",
    "data.loc[:, \"date\"] = pd.to_datetime(data[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T18:23:54.260505Z",
     "start_time": "2021-08-18T18:23:54.218085Z"
    }
   },
   "outputs": [],
   "source": [
    "### Monthly context\n",
    "data[\"year-month\"] = data[\"year\"] + \"-\" + data[\"month\"]\n",
    "\n",
    "### Weekly context\n",
    "data[\"year-week\"] = create_different_time_slices(data)\n",
    "data[\"year-week\"] = data[\"year\"] + \"-\" + data[\"year-week\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T18:23:54.279634Z",
     "start_time": "2021-08-18T18:23:54.265442Z"
    }
   },
   "outputs": [],
   "source": [
    "data[\"target\"] = data[\"club\"].apply(lambda x: 1 if x == positive_case else 0)\n",
    "\n",
    "print(\"The fraction of positive cases is {:.2f}\".format(data[\"target\"].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T18:23:54.346241Z",
     "start_time": "2021-08-18T18:23:54.282551Z"
    }
   },
   "outputs": [],
   "source": [
    "data = exclude_periods_without_positive_case(data, positive_case, \"year-month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T18:23:54.351296Z",
     "start_time": "2021-08-18T18:23:54.348359Z"
    }
   },
   "outputs": [],
   "source": [
    "train_end_date = \"2018-01\"\n",
    "holdout_end_date = \"2021-07\"\n",
    "train_end_year = int(train_end_date.split(\"-\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T18:23:54.371111Z",
     "start_time": "2021-08-18T18:23:54.353287Z"
    }
   },
   "outputs": [],
   "source": [
    "in_time = data[data[\"year-month\"] < train_end_date]\n",
    "\n",
    "train, test = train_test_split(in_time, \n",
    "                               test_size=0.2, \n",
    "                               random_state=42)\n",
    "\n",
    "out_of_time = data[(data[\"year-month\"] >= train_end_date) & (data[\"year-month\"] <= holdout_end_date)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T18:23:54.378060Z",
     "start_time": "2021-08-18T18:23:54.374860Z"
    }
   },
   "outputs": [],
   "source": [
    "target = \"target\"\n",
    "time_column = \"year-month\"\n",
    "time_column = \"year\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T18:23:54.385269Z",
     "start_time": "2021-08-18T18:23:54.380801Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Dataset shapes:\")\n",
    "print(\"Train: {}\".format(train.shape))\n",
    "print(\"Test: {}\".format(test.shape))\n",
    "print(\"Out of time: {}\".format(out_of_time.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T18:23:58.136079Z",
     "start_time": "2021-08-18T18:23:54.388144Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=MAX_VOCABULARY,\n",
    "                             stop_words=STOP_WORDS,\n",
    "                             binary=False,\n",
    "                             use_idf=True,\n",
    "                             norm=False)\n",
    "\n",
    "train_vectors = pd.DataFrame(vectorizer.fit_transform(train[\"text\"]).toarray(), columns=vectorizer.vocabulary_)\n",
    "test_vectors = pd.DataFrame(vectorizer.transform(test[\"text\"]).toarray(), columns=vectorizer.vocabulary_)\n",
    "oot_vectors = pd.DataFrame(vectorizer.transform(out_of_time[\"text\"]).toarray(), columns=vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T18:23:58.142969Z",
     "start_time": "2021-08-18T18:23:58.138321Z"
    }
   },
   "outputs": [],
   "source": [
    "train_vectors[time_column] = train[time_column].values\n",
    "test_vectors[time_column] = test[time_column].values\n",
    "oot_vectors[time_column] = out_of_time[time_column].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T18:23:58.147496Z",
     "start_time": "2021-08-18T18:23:58.144953Z"
    }
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(max_depth=10, n_estimators=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T18:23:58.373319Z",
     "start_time": "2021-08-18T18:23:58.149433Z"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(train_vectors.drop(columns=[\"year\"]), train[\"target\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T18:23:58.413794Z",
     "start_time": "2021-08-18T18:23:58.375286Z"
    }
   },
   "outputs": [],
   "source": [
    "train[\"prediction\"] = model.predict_proba(train_vectors.drop(columns=[\"year\"]))[:, 1]\n",
    "roc_auc_score(train[target], train[\"prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T18:23:58.439491Z",
     "start_time": "2021-08-18T18:23:58.416078Z"
    }
   },
   "outputs": [],
   "source": [
    "test[\"prediction\"] = model.predict_proba(test_vectors.drop(columns=[\"year\"]))[:, 1]\n",
    "roc_auc_score(test[target], test[\"prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T18:23:58.542267Z",
     "start_time": "2021-08-18T18:23:58.446519Z"
    }
   },
   "outputs": [],
   "source": [
    "out_of_time[\"prediction\"] = model.predict_proba(oot_vectors.drop(columns=[\"year\"]))[:, 1]\n",
    "roc_auc_score(out_of_time[target], out_of_time[\"prediction\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize Random Forest and lgbm benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T18:24:37.831011Z",
     "start_time": "2021-08-18T18:24:36.202425Z"
    }
   },
   "outputs": [],
   "source": [
    "from pycaret.classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T18:24:37.835704Z",
     "start_time": "2021-08-18T18:24:37.833248Z"
    }
   },
   "outputs": [],
   "source": [
    "train_features = pd.DataFrame(train_vectors)\n",
    "oot_features = pd.DataFrame(oot_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T18:24:38.115423Z",
     "start_time": "2021-08-18T18:24:38.112689Z"
    }
   },
   "outputs": [],
   "source": [
    "features = [col for col in train_features.columns if col != time_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_data_opt = oot_features.copy(deep=True)\n",
    "holdout_data_opt[target] = out_of_time[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_opt = pd.DataFrame(test_vectors).copy(deep=True)\n",
    "test_data_opt[target] = test[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T18:24:41.102889Z",
     "start_time": "2021-08-18T18:24:41.084938Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_opt = train_features.copy(deep=True)\n",
    "train_data_opt[target] = train[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T18:24:41.670498Z",
     "start_time": "2021-08-18T18:24:41.667321Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_opt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T18:26:58.021476Z",
     "start_time": "2021-08-18T18:25:16.725861Z"
    }
   },
   "outputs": [],
   "source": [
    "clf1 = setup(train_data_opt[features + [target]],\n",
    "             target=\"target\",\n",
    "             log_experiment=False, \n",
    "             experiment_name=\"ge_exp\",\n",
    "             silent=True)\n",
    "\n",
    "#best_model = compare_models()\n",
    "\n",
    "rf = create_model('rf')\n",
    "tuned_rf = tune_model(rf,\n",
    "                     optimize=\"AUC\",\n",
    "                     fold=5,\n",
    "                     n_iter=50)\n",
    "\n",
    "lgbm = create_model(\"lightgbm\")\n",
    "\n",
    "tuned_lgbm = tune_model(lgbm,\n",
    "                        fold=5,\n",
    "                        n_iter=50,\n",
    "                        optimize=\"AUC\")\n",
    "\n",
    "plot_model(tuned_lgbm, plot=\"feature\")\n",
    "interpret_model(tuned_lgbm)\n",
    "\n",
    "best = automl(optimize='AUC')\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T18:26:58.032068Z",
     "start_time": "2021-08-18T18:26:58.025075Z"
    }
   },
   "outputs": [],
   "source": [
    "tuned_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T18:26:58.041356Z",
     "start_time": "2021-08-18T18:26:58.037410Z"
    }
   },
   "outputs": [],
   "source": [
    "benchmark = tuned_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T18:26:58.736811Z",
     "start_time": "2021-08-18T18:26:58.046505Z"
    }
   },
   "outputs": [],
   "source": [
    "benchmark.fit(train_vectors.drop(columns=[\"year\"]), train[\"target\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T18:27:02.709585Z",
     "start_time": "2021-08-18T18:26:58.739651Z"
    }
   },
   "outputs": [],
   "source": [
    "interpret_model(benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T18:27:02.842465Z",
     "start_time": "2021-08-18T18:27:02.712028Z"
    }
   },
   "outputs": [],
   "source": [
    "train[\"prediction_rf\"] = benchmark.predict_proba(train_vectors.drop(columns=[\"year\"]))[:, 1]\n",
    "roc_auc_score(train[target], train[\"prediction_rf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T18:27:02.966713Z",
     "start_time": "2021-08-18T18:27:02.844769Z"
    }
   },
   "outputs": [],
   "source": [
    "test[\"prediction_rf\"] = benchmark.predict_proba(test_vectors.drop(columns=[\"year\"]))[:, 1]\n",
    "roc_auc_score(test[target], test[\"prediction_rf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T18:27:03.135989Z",
     "start_time": "2021-08-18T18:27:02.970257Z"
    }
   },
   "outputs": [],
   "source": [
    "out_of_time[\"prediction_rf\"] = benchmark.predict_proba(oot_vectors.drop(columns=[\"year\"]))[:, 1]\n",
    "roc_auc_score(out_of_time[target], out_of_time[\"prediction_rf\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T18:27:03.142692Z",
     "start_time": "2021-08-18T18:27:03.138322Z"
    }
   },
   "outputs": [],
   "source": [
    "tuned_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T18:27:03.600852Z",
     "start_time": "2021-08-18T18:27:03.144961Z"
    }
   },
   "outputs": [],
   "source": [
    "benchmark = tuned_lgbm\n",
    "benchmark.fit(train_vectors.drop(columns=[\"year\"]), train[\"target\"].values)\n",
    "train[\"prediction_lgbm\"] = benchmark.predict_proba(train_vectors.drop(columns=[\"year\"]))[:, 1]\n",
    "print(roc_auc_score(train[target], train[\"prediction_lgbm\"]))\n",
    "\n",
    "test[\"prediction_lgbm\"] = benchmark.predict_proba(test_vectors.drop(columns=[\"year\"]))[:, 1]\n",
    "print(roc_auc_score(test[target], test[\"prediction_lgbm\"]))\n",
    "\n",
    "out_of_time[\"prediction_lgbm\"] = benchmark.predict_proba(oot_vectors.drop(columns=[\"year\"]))[:, 1]\n",
    "print(roc_auc_score(out_of_time[target], out_of_time[\"prediction_lgbm\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = train_data_opt\n",
    "test_ = test_data_opt\n",
    "out_of_time_ = holdout_data_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = reverse_learning_curve(train_, out_of_time_, tuned_rf, features, target, time_column, roc_auc_score, n_rounds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_importances = results[\"feature_importance\"][-1].copy(deep=True)\n",
    "benchmark_importances.rename(\"RF\", inplace=True)\n",
    "benchmark_importances.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "blues = plt.get_cmap(\"Blues\")\n",
    "gradient = np.linspace(.2, 0.8, len(results[\"holdout_performance\"]))\n",
    "\n",
    "for i, r in enumerate(results[\"holdout_performance_by_period\"]):\n",
    "    r.plot(label=results[\"last_period_included\"][i], color=blues(gradient[i]))\n",
    "\n",
    "ax.xaxis.set_tick_params(labelsize=12)\n",
    "ax.yaxis.set_tick_params(labelsize=12)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), fontsize=12, title=\"Oldest time period included in train\")\n",
    "plt.ylabel(\"AUC\", fontsize=15)\n",
    "plt.xlabel(\"Year\", fontsize=15)\n",
    "\n",
    "plt.savefig(\"../images/{}_perf_by_period_reverse_learning_curve_benchmark.eps\".format(PREFIX), format=\"eps\", bbox_inches = \"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHALLENGER_N_ESTIMATORS = 60\n",
    "CHALLENGER_MAX_DEPTH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T19:31:16.867174Z",
     "start_time": "2021-08-18T18:34:15.868738Z"
    }
   },
   "outputs": [],
   "source": [
    "time_model = TimeForestClassifier(n_estimators=CHALLENGER_N_ESTIMATORS, \n",
    "                                  time_column=time_column, \n",
    "                                  max_depth=CHALLENGER_MAX_DEPTH,\n",
    "                                  min_sample_periods=10,\n",
    "                                  max_features=1.0,\n",
    "                                  n_jobs=-1,\n",
    "                                  criterion=\"std\",\n",
    "                                  multi=True)\n",
    "\n",
    "time_model.fit(train_vectors, train[\"target\"].values)\n",
    "\n",
    "train[\"time_prediction\"] = time_model.predict_proba_(train_vectors)\n",
    "print(roc_auc_score(train[target], train[\"time_prediction\"]))\n",
    "\n",
    "test[\"time_prediction\"] = time_model.predict_proba_(test_vectors)\n",
    "print(roc_auc_score(test[target], test[\"time_prediction\"]))\n",
    "\n",
    "out_of_time[\"time_prediction\"] = time_model.predict_proba_(oot_vectors)\n",
    "print(roc_auc_score(out_of_time[target], out_of_time[\"time_prediction\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T19:31:17.355245Z",
     "start_time": "2021-08-18T19:31:16.871777Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_model.feature_importance()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenger_model = TimeForestClassifier(n_estimators=CHALLENGER_N_ESTIMATORS, \n",
    "                                  time_column=time_column, \n",
    "                                  max_depth=CHALLENGER_MAX_DEPTH,\n",
    "                                  min_sample_periods=10,\n",
    "                                  max_features=1.0,\n",
    "                                  n_jobs=-1,\n",
    "                                  criterion=\"std\",\n",
    "                                  multi=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_trt = reverse_learning_curve(train_, out_of_time_, challenger_model, features, target, time_column, roc_auc_score, n_rounds=5, trt_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenger_model_importances = results_trt[\"feature_importance\"][-1].copy(deep=True)\n",
    "challenger_model_importances.rename(\"TRF\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models_importance = pd.DataFrame(index=features)\n",
    "all_models_importance = all_models_importance.merge(benchmark_importances, how=\"left\", left_index=True, \n",
    "                            right_index=True)\n",
    "all_models_importance = all_models_importance.merge(challenger_model_importances, how=\"left\", left_index=True, \n",
    "                            right_index=True)\n",
    "\n",
    "\n",
    "all_models_importance.fillna(0, inplace=True)\n",
    "all_models_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "greens = plt.get_cmap(\"Greens\")\n",
    "gradient = np.linspace(.2, 0.8, len(results_trt[\"holdout_performance\"]))\n",
    "\n",
    "for i, r in enumerate(results_trt[\"holdout_performance_by_period\"]):\n",
    "    r.plot(label=results_trt[\"last_period_included\"][i], color=greens(gradient[i]))\n",
    "\n",
    "ax.xaxis.set_tick_params(labelsize=12)\n",
    "ax.yaxis.set_tick_params(labelsize=12)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), fontsize=12, title=\"Oldest time period included in train\")\n",
    "plt.ylabel(\"AUC\", fontsize=15)\n",
    "plt.xlabel(\"Year\", fontsize=15)\n",
    "\n",
    "plt.savefig(\"../images/{}_perf_by_period_reverse_learning_curve_challenger.eps\".format(PREFIX), format=\"eps\", bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.plot([str(i) for i in results[\"sample_size\"]], results[\"holdout_performance\"], label=\"RF\")\n",
    "plt.plot(results_trt[\"holdout_performance\"], label=\"TRF\", linestyle=\"dashed\", color=\"green\")\n",
    "ax.xaxis.set_tick_params(labelsize=12)\n",
    "ax.yaxis.set_tick_params(labelsize=12)\n",
    "plt.legend(fontsize=15, bbox_to_anchor=(1.0, 1.0))\n",
    "plt.ylabel(\"AUC in the holdout\", fontsize=15)\n",
    "plt.xlabel(\"Sample size\", fontsize=15)\n",
    "plt.savefig(\"../images/{}_reverse_learning_curve_sample.eps\".format(PREFIX), format=\"eps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.plot([str(i) for i in results[\"last_period_included\"]], results[\"holdout_performance\"], label=\"RF\")\n",
    "plt.plot(results_trt[\"holdout_performance\"], label=\"TRF\", linestyle=\"dashed\", color=\"green\")\n",
    "ax.xaxis.set_tick_params(labelsize=12)\n",
    "ax.yaxis.set_tick_params(labelsize=12)\n",
    "plt.legend(fontsize=15, bbox_to_anchor=(1.0, 1.0))\n",
    "plt.ylabel(\"AUC in the holdout\", fontsize=15)\n",
    "plt.xlabel(\"Oldest time period included in the training\", fontsize=15)\n",
    "plt.savefig(\"../images/{}_reverse_learning_curve_segments.eps\".format(PREFIX), format=\"eps\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "greens = plt.get_cmap(\"Greens\")\n",
    "gradient = np.linspace(.2, 0.8, len(results_trt[\"holdout_performance\"]))\n",
    "\n",
    "for i, r in enumerate(results_trt[\"holdout_performance_by_period\"]):\n",
    "    r.plot(label=results_trt[\"last_period_included\"][i], color=greens(gradient[i]))\n",
    "    \n",
    "for i, r in enumerate(results[\"holdout_performance_by_period\"]):\n",
    "    r.plot(label=results[\"last_period_included\"][i], color=blues(gradient[i]))\n",
    "\n",
    "ax.xaxis.set_tick_params(labelsize=12)\n",
    "ax.yaxis.set_tick_params(labelsize=12)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), fontsize=12, title=\"Oldest time period included in train\")\n",
    "plt.ylabel(\"AUC\", fontsize=15)\n",
    "plt.xlabel(\"Year\", fontsize=15)\n",
    "\n",
    "plt.savefig(\"../images/{}_perf_by_period_reverse_learning_curve_both.eps\".format(PREFIX), format=\"eps\", bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T19:31:17.728166Z",
     "start_time": "2021-08-18T19:31:17.358581Z"
    }
   },
   "outputs": [],
   "source": [
    "out_of_time.groupby(time_column).apply(lambda x: roc_auc_score(x[target], x[\"time_prediction\"])).plot(label=\"Time Forest\")\n",
    "out_of_time.groupby(time_column).apply(lambda x: roc_auc_score(x[target], x[\"prediction_rf\"])).plot(label=\"Random Forest\")\n",
    "out_of_time.groupby(time_column).apply(lambda x: roc_auc_score(x[target], x[\"prediction_lgbm\"])).plot(label=\"LGBM\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"AUC by year for TimeTree and DecisionTree on the GE Club News dataset\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T19:31:18.007854Z",
     "start_time": "2021-08-18T19:31:17.730590Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.concat([test, out_of_time]).groupby(time_column).apply(lambda x: roc_auc_score(x[target], x[\"time_prediction\"])).plot(label=\"Time Forest\")\n",
    "pd.concat([test, out_of_time]).groupby(time_column).apply(lambda x: roc_auc_score(x[target], x[\"prediction_rf\"])).plot(label=\"Random Forest\")\n",
    "pd.concat([test, out_of_time]).groupby(time_column).apply(lambda x: roc_auc_score(x[target], x[\"prediction_lgbm\"])).plot(label=\"LGBM\")\n",
    "\n",
    "xmin, xmax, ymin, ymax = plt.axis()\n",
    "plt.vlines(4, ymin, ymax, linestyle=\"dotted\", color=\"red\", label=\"Out of time split\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0))\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0))\n",
    "plt.title(\"AUC by year for TimeTree and DecisionTree on the GE Club News dataset\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-18T19:31:18.350086Z",
     "start_time": "2021-08-18T19:31:18.009757Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "pd.concat([test, out_of_time]).groupby(time_column).apply(lambda x: roc_auc_score(x[target], x[\"time_prediction\"])).plot(label=\"Time Robust Forest\",\n",
    "                                                                                                                        color=\"green\", linestyle=\"dashed\")\n",
    "pd.concat([test, out_of_time]).groupby(time_column).apply(lambda x: roc_auc_score(x[target], x[\"prediction_rf\"])).plot(label=\"Random Forest\", \n",
    "                                                                                                                       linestyle=\"-.\")\n",
    "pd.concat([test, out_of_time]).groupby(time_column).apply(lambda x: roc_auc_score(x[target], x[\"prediction_lgbm\"])).plot(label=\"LGBM\", color=\"orange\")\n",
    "\n",
    "ax.xaxis.set_tick_params(labelsize=12)\n",
    "ax.yaxis.set_tick_params(labelsize=12)\n",
    "\n",
    "xmin, xmax, ymin, ymax = plt.axis()\n",
    "plt.ylim([ymin, ymax])\n",
    "plt.vlines(4, ymin, ymax, linestyle=\"dotted\", color=\"red\", label=\"Holdout start\")\n",
    "#plt.legend(bbox_to_anchor=(1.05, 1.0))\n",
    "plt.legend(fontsize=15, bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "#plt.legend(bbox_to_anchor=(1.05, 1.0))\n",
    "#plt.title(\"AUC by year for TimeTree and DecisionTree on the GE Club News dataset\")\n",
    "\n",
    "plt.ylabel(\"AUC\", fontsize=15)\n",
    "plt.xlabel(\"Year\", fontsize=15)\n",
    "#plt.savefig(\"images/ge_sklearn.eps\", format=\"eps\", bbox_inches=\"tight\")\n",
    "plt.savefig(\"../images/{}_sklearn_binary.eps\".format(PREFIX), format=\"eps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimum samples by period effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sample_periods_values = [1, 5, 10, 20, 50, 100, 250, 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sample_knob = {}\n",
    "min_sample_knob[\"challenger\"] = {\"unseen_performance\": [], \"train_performance\": [],\n",
    "                                \"test_performance\": [], \"unseen_performance_by_period\": []}\n",
    "unseen_performance = []\n",
    "train_performance = []\n",
    "test_performance = []\n",
    "unseen_performance_by_period = []\n",
    "\n",
    "for min_sample_periods in min_sample_periods_values:\n",
    "    model_split_time = TimeForestClassifier(time_column=time_column,\n",
    "                                        n_estimators=CHALLENGER_N_ESTIMATORS,\n",
    "                                        min_sample_periods=min_sample_periods,\n",
    "                                        max_depth=CHALLENGER_MAX_DEPTH,\n",
    "                                        multi=True)\n",
    "    \n",
    "    model_split_time.fit(train_[features + [time_column]], train_[target])\n",
    "    out_of_time_[\"time_split_prediction\"] = model_split_time.predict_proba(out_of_time_[features])[:, 1]\n",
    "    \n",
    "    performance = metrics.roc_auc_score(out_of_time_[target], out_of_time_[\"time_split_prediction\"])\n",
    "    min_sample_knob[\"challenger\"][\"unseen_performance\"].append(performance)\n",
    "    min_sample_knob[\"challenger\"][\"unseen_performance_by_period\"].append(out_of_time_.groupby(time_column).apply(lambda x: roc_auc_score(x[target], x[\"time_split_prediction\"])))\n",
    "\n",
    "    train_[\"time_split_prediction\"] = model_split_time.predict(train_[features])\n",
    "    min_sample_knob[\"challenger\"][\"train_performance\"].append(metrics.roc_auc_score(train_[target], train_[\"time_split_prediction\"]))\n",
    "    \n",
    "    test_[\"time_split_prediction\"] = model_split_time.predict(test_[features])\n",
    "    min_sample_knob[\"challenger\"][\"test_performance\"].append(metrics.roc_auc_score(test_[target], test_[\"time_split_prediction\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.plot(min_sample_periods_values, min_sample_knob[\"challenger\"][\"train_performance\"], label=\"Train\")\n",
    "plt.plot(min_sample_periods_values, min_sample_knob[\"challenger\"][\"test_performance\"], label=\"Test\", \n",
    "         color=\"magenta\",\n",
    "         linestyle=\"dotted\")\n",
    "plt.plot(min_sample_periods_values, min_sample_knob[\"challenger\"][\"unseen_performance\"], label=\"Holdout\", \n",
    "                                                         linestyle=\"dashed\",\n",
    "                                                         color=\"green\")\n",
    "\n",
    "#plt.title(\"Holdout AUC by minimum examples by period parameter\", fontsize=15)\n",
    "ax.xaxis.set_tick_params(labelsize=12)\n",
    "ax.yaxis.set_tick_params(labelsize=12)\n",
    "xmin, xmax, ymin, ymax = plt.axis()\n",
    "plt.ylim([ymin, ymax])\n",
    "plt.legend(fontsize=15)\n",
    "plt.ylabel(\"AUC\", fontsize=15)\n",
    "plt.xlabel(\"Minimum examples by period\", fontsize=15)\n",
    "plt.savefig(\"../images/{}_test_min_example_by_period_train_and_holdout_whole.eps\".format(PREFIX), format=\"eps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "greens = plt.get_cmap(\"Greens\")\n",
    "gradient = np.linspace(.1, 0.9, len(min_sample_periods_values))\n",
    "for i, experiment in enumerate(min_sample_knob[\"challenger\"][\"unseen_performance_by_period\"]):\n",
    "    experiment.plot(label=min_sample_periods_values[i], color=greens(gradient[i]))\n",
    "\n",
    "out_of_time.groupby(time_column).apply(lambda x: roc_auc_score(x[target], x[\"prediction_rf\"])).plot(label=\"Optimal RF benchmark\", \n",
    "                                                                                                 color=\"red\", linestyle=\"dashed\", ax=ax)\n",
    "ax.xaxis.set_tick_params(labelsize=12)\n",
    "ax.yaxis.set_tick_params(labelsize=12)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), fontsize=12, title=\"Minimum examples by period\")\n",
    "plt.ylabel(\"AUC\", fontsize=15)\n",
    "plt.xlabel(\"Year\", fontsize=15)\n",
    "\n",
    "x_labels = np.sort(out_of_time[time_column].unique())\n",
    "#plt.xticks(x_labels)\n",
    "\n",
    "plt.savefig(\"../images/{}_holdout_dif_min_samples.eps\".format(PREFIX), format=\"eps\", bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sample_knob[\"benchmark\"] = {\"unseen_performance\": [], \"train_performance\": [],\n",
    "                                \"test_performance\": [], \"unseen_performance_by_period\": []}\n",
    "\n",
    "training_segments = train[time_column].nunique()\n",
    "for min_sample_periods in min_sample_periods_values:\n",
    "\n",
    "    model = tuned_rf\n",
    "    model.set_params(min_samples_leaf=training_segments * min_sample_periods)\n",
    "    \n",
    "    \n",
    "    model.fit(train_[features],\n",
    "              train_[target])\n",
    "     \n",
    "    out_of_time_[\"time_split_prediction\"] = model.predict_proba(out_of_time_[features])[:, 1]\n",
    "    \n",
    "    performance = metrics.roc_auc_score(out_of_time_[target], out_of_time_[\"time_split_prediction\"])\n",
    "    min_sample_knob[\"benchmark\"][\"unseen_performance\"].append(performance)\n",
    "    min_sample_knob[\"benchmark\"][\"unseen_performance_by_period\"].append(out_of_time_.groupby(time_column).apply(lambda x: roc_auc_score(x[target], x[\"time_split_prediction\"])))\n",
    "\n",
    "    train_[\"time_split_prediction\"] = model.predict(train_[features])\n",
    "    min_sample_knob[\"benchmark\"][\"train_performance\"].append(metrics.roc_auc_score(train_[target], train_[\"time_split_prediction\"]))\n",
    "    \n",
    "    test_[\"time_split_prediction\"] = model.predict(test_[features])\n",
    "    min_sample_knob[\"benchmark\"][\"test_performance\"].append(metrics.roc_auc_score(test_[target], test_[\"time_split_prediction\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "blues = plt.get_cmap(\"Blues\")\n",
    "for i, experiment in enumerate(min_sample_knob[\"benchmark\"][\"unseen_performance_by_period\"]):\n",
    "    experiment.plot(label=min_sample_periods_values[i], color=blues(gradient[i]))\n",
    "\n",
    "out_of_time.groupby(time_column).apply(lambda x: roc_auc_score(x[target], x[\"prediction_rf\"])).plot(label=\"Optimal RF benchmark\", \n",
    "                                                                                                 color=\"red\", linestyle=\"dashed\", ax=ax)\n",
    "\n",
    "ax.xaxis.set_tick_params(labelsize=12)\n",
    "ax.yaxis.set_tick_params(labelsize=12)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), fontsize=12, title=\"Minimum examples by period\")\n",
    "plt.ylabel(\"AUC\", fontsize=15)\n",
    "plt.xlabel(\"Year\", fontsize=15)\n",
    "\n",
    "x_labels = np.sort(out_of_time[time_column].unique())\n",
    "#plt.xticks(x_labels)\n",
    "\n",
    "plt.savefig(\"../images/{}_holdout_dif_min_samples_benchmark.eps\".format(PREFIX), format=\"eps\", bbox_inches = \"tight\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for i, experiment in enumerate(min_sample_knob[\"challenger\"][\"unseen_performance_by_period\"]):\n",
    "    experiment.plot(label=min_sample_periods_values[i], color=greens(gradient[i]))\n",
    "    \n",
    "for i, experiment in enumerate(min_sample_knob[\"benchmark\"][\"unseen_performance_by_period\"]):\n",
    "    experiment.plot(label=min_sample_periods_values[i], color=blues(gradient[i]))    \n",
    "\n",
    "ax.xaxis.set_tick_params(labelsize=12)\n",
    "ax.yaxis.set_tick_params(labelsize=12)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), fontsize=12, title=\"Minimum examples by period\")\n",
    "plt.ylabel(\"AUC\", fontsize=15)\n",
    "plt.xlabel(\"Year\", fontsize=15)\n",
    "\n",
    "x_labels = np.sort(out_of_time[time_column].unique())\n",
    "#plt.xticks(x_labels)\n",
    "\n",
    "plt.savefig(\"../images/{}_holdout_dif_min_samples_benchmark_challenger.eps\".format(PREFIX), format=\"eps\", bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.plot(min_sample_periods_values, min_sample_knob[\"challenger\"][\"train_performance\"], label=\"TRF Train\",\n",
    "        color=\"#4c72b0\", linestyle=\"dashed\")\n",
    "plt.plot(min_sample_periods_values, min_sample_knob[\"challenger\"][\"test_performance\"], label=\"TRF Test\", \n",
    "         color=\"magenta\",\n",
    "         linestyle=\"dashed\")\n",
    "plt.plot(min_sample_periods_values, min_sample_knob[\"challenger\"][\"unseen_performance\"], label=\"TRF Holdout\", \n",
    "                                                         linestyle=\"dashed\",\n",
    "                                                         color=\"green\")\n",
    "\n",
    "plt.plot(min_sample_periods_values, min_sample_knob[\"benchmark\"][\"train_performance\"], label=\"RF Train\",\n",
    "        color=\"#4c72b0\")\n",
    "plt.plot(min_sample_periods_values, min_sample_knob[\"benchmark\"][\"test_performance\"], label=\"RF Test\", \n",
    "         color=\"magenta\")\n",
    "plt.plot(min_sample_periods_values, min_sample_knob[\"benchmark\"][\"unseen_performance\"], label=\"RF Holdout\", \n",
    "                                                         color=\"green\")\n",
    "\n",
    "#plt.title(\"Holdout AUC by minimum examples by period parameter\", fontsize=15)\n",
    "ax.xaxis.set_tick_params(labelsize=12)\n",
    "ax.yaxis.set_tick_params(labelsize=12)\n",
    "xmin, xmax, ymin, ymax = plt.axis()\n",
    "plt.ylim([ymin, ymax])\n",
    "plt.legend(fontsize=15)\n",
    "plt.ylabel(\"AUC\", fontsize=15)\n",
    "plt.xlabel(\"Minimum examples by period\", fontsize=15)\n",
    "plt.savefig(\"../images/{}_test_min_example_by_period_train_and_holdout_whole_bench_challenger.eps\".format(PREFIX), format=\"eps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "plt.plot(min_sample_periods_values, min_sample_knob[\"challenger\"][\"unseen_performance\"], label=\"TRF Holdout\", \n",
    "                                                         linestyle=\"dashed\",\n",
    "                                                         color=\"green\")\n",
    "\n",
    "plt.plot(min_sample_periods_values, min_sample_knob[\"benchmark\"][\"unseen_performance\"], label=\"RF Holdout\", \n",
    "                                                         color=\"green\")\n",
    "\n",
    "#plt.title(\"Holdout AUC by minimum examples by period parameter\", fontsize=15)\n",
    "ax.xaxis.set_tick_params(labelsize=12)\n",
    "ax.yaxis.set_tick_params(labelsize=12)\n",
    "xmin, xmax, ymin, ymax = plt.axis()\n",
    "plt.ylim([ymin, ymax])\n",
    "plt.legend(fontsize=15)\n",
    "plt.ylabel(\"AUC\", fontsize=15)\n",
    "plt.xlabel(\"Minimum examples by period\", fontsize=15)\n",
    "plt.savefig(\"../images/{}_holdout_min_example_by_period_train_and_holdout_whole_bench_challenger.eps\".format(PREFIX), format=\"eps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_[\"domain\"] = 1\n",
    "test_[\"domain\"] = 1\n",
    "out_of_time_[\"domain\"] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_data = pd.concat([train_, test_, out_of_time_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_domain, test_domain = train_test_split(domain_data, \n",
    "                               test_size=0.2,\n",
    "                               random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_domain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = setup(train_domain[features + [\"domain\"]], target=\"domain\",\n",
    "             session_id=124, \n",
    "             log_experiment=False, \n",
    "             experiment_name=\"{}_domain\".format(PREFIX),\n",
    "             silent=True)\n",
    "\n",
    "rf = create_model('rf')\n",
    "tuned_domain_rf = tune_model(rf,\n",
    "                             optimize=\"AUC\",\n",
    "                             fold=5,\n",
    "                             n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_model = tuned_domain_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_model.fit(train_domain[features], train_domain[\"domain\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_domain[\"pred_domain\"] = domain_model.predict_proba(test_domain[features])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(test_domain[\"domain\"], test_domain[\"pred_domain\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other optiomization design for the RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_time_segment_in_train = np.max(in_time[time_column].unique())\n",
    "last_time_segment_in_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posfix = str(last_time_segment_in_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_time = pd.concat([train_, test_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = in_time[in_time[time_column] < last_time_segment_in_train]\n",
    "new_validation = in_time[in_time[time_column] == last_time_segment_in_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = setup(new_train[features + [target]], target=target,\n",
    "             test_data=new_validation,\n",
    "             session_id=44,\n",
    "             log_experiment=False,\n",
    "             experiment_name=\"{}_opt1\".format(PREFIX),\n",
    "             silent=True)\n",
    "\n",
    "rf = create_model('rf')\n",
    "tuned_rf = tune_model(rf,\n",
    "                      optimize=\"AUC\",\n",
    "                      n_iter=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_model = tuned_rf\n",
    "benchmark_model.fit(train_[features], train_[target])\n",
    "\n",
    "train[\"benchmark_prediction_opt_{}\".format(posfix)] = benchmark_model.predict_proba(train_[features])[:, 1]\n",
    "test[\"benchmark_prediction_opt_{}\".format(posfix)] = benchmark_model.predict_proba(test_[features])[:, 1]\n",
    "out_of_time[\"benchmark_prediction_opt_{}\".format(posfix)] = benchmark_model.predict_proba(out_of_time_[features])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_validation, add_to_train = train_test_split(new_validation, test_size=0.5)\n",
    "\n",
    "new_train = pd.concat([new_train, add_to_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = setup(new_train[features + [target]], target=target,\n",
    "             test_data=new_validation,\n",
    "             session_id=22,\n",
    "             log_experiment=False,\n",
    "             experiment_name=\"{}_opt2\".format(PREFIX),\n",
    "             silent=True)\n",
    "\n",
    "rf = create_model('rf')\n",
    "tuned_rf = tune_model(rf,\n",
    "                     optimize=\"AUC\",\n",
    "                     n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_model = tuned_rf\n",
    "benchmark_model.fit(train_[features], train_[target])\n",
    "\n",
    "train[\"benchmark_prediction_opt_half_{}\".format(posfix)] = benchmark_model.predict_proba(train_[features])[:, 1]\n",
    "test[\"benchmark_prediction_opt_half_{}\".format(posfix)] = benchmark_model.predict_proba(test_[features])[:, 1]\n",
    "out_of_time[\"benchmark_prediction_opt_half_{}\".format(posfix)] = benchmark_model.predict_proba(out_of_time_[features])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "pd.concat([test, out_of_time]).groupby(time_column).apply(lambda x: roc_auc_score(x[target], x[\"time_prediction\"])).plot(label=\"Time Robust Forest\", \n",
    "                                                                                                      linestyle=\"dashed\",\n",
    "                                                                                                      color=\"green\", ax=ax)\n",
    "\n",
    "pd.concat([test, out_of_time]).groupby(time_column).apply(lambda x: roc_auc_score(x[target], x[\"benchmark_prediction_opt_half_{}\".format(posfix)])).plot(label=\"RF: Half {} in validation\".format(posfix), \n",
    "                                                                                                      #linestyle=\"dashed\",\n",
    "                                                                                                      color=\"purple\", ax=ax)\n",
    "pd.concat([test, out_of_time]).groupby(time_column).apply(lambda x: roc_auc_score(x[target], x[\"prediction_rf\"])).plot(label=\"RF: K-fold in the in-time\", ax=ax)\n",
    "pd.concat([test, out_of_time]).groupby(time_column).apply(lambda x: roc_auc_score(x[target], x[\"benchmark_prediction_opt_{}\".format(posfix)])).plot(label=\"RF: Full {} in validation\".format(posfix), ax=ax)\n",
    "\n",
    "ax.xaxis.set_tick_params(labelsize=12)\n",
    "ax.yaxis.set_tick_params(labelsize=12)\n",
    "\n",
    "xmin, xmax, ymin, ymax = plt.axis()\n",
    "plt.vlines(4, ymin, ymax, linestyle=\"dotted\", color=\"red\", label=\"Holdout start\")\n",
    "plt.ylim([ymin, ymax])\n",
    "plt.legend(fontsize=15, bbox_to_anchor=(1.0, 1.0))\n",
    "plt.ylabel(\"AUC\", fontsize=15)\n",
    "plt.xlabel(\"Year\", fontsize=15)\n",
    "plt.savefig(\"../images/{}_performance_proof.eps\".format(PREFIX), format=\"eps\", bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:.conda-msc]",
   "language": "python",
   "name": "conda-env-.conda-msc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Index",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
