{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example - Chicago Crime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Index<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Create-a-target\" data-toc-modified-id=\"Create-a-target-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Create a target</a></span></li><li><span><a href=\"#Modeling\" data-toc-modified-id=\"Modeling-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Modeling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data\" data-toc-modified-id=\"Data-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Data</a></span></li></ul></li><li><span><a href=\"#Checking-the-support-in-the-different-environments\" data-toc-modified-id=\"Checking-the-support-in-the-different-environments-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Checking the support in the different environments</a></span><ul class=\"toc-item\"><li><span><a href=\"#Benchmark\" data-toc-modified-id=\"Benchmark-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Benchmark</a></span></li></ul></li><li><span><a href=\"#Challenger-model\" data-toc-modified-id=\"Challenger-model-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Challenger model</a></span></li><li><span><a href=\"#TRF-as-feature-selection\" data-toc-modified-id=\"TRF-as-feature-selection-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>TRF as feature selection</a></span></li><li><span><a href=\"#Domain-classifier\" data-toc-modified-id=\"Domain-classifier-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Domain classifier</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T16:52:31.740769Z",
     "start_time": "2021-06-26T16:52:31.736512Z"
    },
    "execution": {
     "iopub.execute_input": "2021-08-18T23:48:54.455864Z",
     "iopub.status.busy": "2021-08-18T23:48:54.455525Z",
     "iopub.status.idle": "2021-08-18T23:48:59.644831Z",
     "shell.execute_reply": "2021-08-18T23:48:59.643791Z",
     "shell.execute_reply.started": "2021-08-18T23:48:54.455825Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import shap\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics\n",
    "from time_robust_forest.models import TimeForestClassifier\n",
    "from time_robust_forest.functions import check_categoricals_match, check_numerical_match\n",
    "from models.aux_functions import *\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T16:52:33.359680Z",
     "start_time": "2021-06-26T16:52:33.356688Z"
    },
    "execution": {
     "iopub.execute_input": "2021-08-18T23:48:59.647121Z",
     "iopub.status.busy": "2021-08-18T23:48:59.646558Z",
     "iopub.status.idle": "2021-08-18T23:48:59.651971Z",
     "shell.execute_reply": "2021-08-18T23:48:59.651236Z",
     "shell.execute_reply.started": "2021-08-18T23:48:59.647080Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_style():\n",
    "    plt.style.use(['seaborn-white', 'seaborn-paper'])\n",
    "    plt.rcParams['figure.figsize'] = (12, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T16:52:33.784329Z",
     "start_time": "2021-06-26T16:52:33.781776Z"
    },
    "execution": {
     "iopub.execute_input": "2021-08-18T23:48:59.654604Z",
     "iopub.status.busy": "2021-08-18T23:48:59.654082Z",
     "iopub.status.idle": "2021-08-18T23:48:59.677632Z",
     "shell.execute_reply": "2021-08-18T23:48:59.676687Z",
     "shell.execute_reply.started": "2021-08-18T23:48:59.654564Z"
    }
   },
   "outputs": [],
   "source": [
    "set_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T16:52:34.054791Z",
     "start_time": "2021-06-26T16:52:34.052577Z"
    },
    "execution": {
     "iopub.execute_input": "2021-08-18T23:48:59.679625Z",
     "iopub.status.busy": "2021-08-18T23:48:59.679315Z",
     "iopub.status.idle": "2021-08-18T23:48:59.683875Z",
     "shell.execute_reply": "2021-08-18T23:48:59.682954Z",
     "shell.execute_reply.started": "2021-08-18T23:48:59.679587Z"
    }
   },
   "outputs": [],
   "source": [
    "DATASETS_PATH = \"~/Documents/datasets/chicago_crime/\"\n",
    "PREFIX = \"chicago_crime\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T16:52:35.041247Z",
     "start_time": "2021-06-26T16:52:34.254730Z"
    },
    "execution": {
     "iopub.execute_input": "2021-08-18T23:48:59.691614Z",
     "iopub.status.busy": "2021-08-18T23:48:59.685219Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 1149094: expected 23 fields, saw 41\\n'\n"
     ]
    }
   ],
   "source": [
    "data_files = [\"Chicago_Crimes_2012_to_2017.csv.zip\",\n",
    "              \"Chicago_Crimes_2008_to_2011.csv.zip\",\n",
    "              \"Chicago_Crimes_2005_to_2007.csv.zip\",\n",
    "              \"Chicago_Crimes_2001_to_2004.csv.zip\"]\n",
    "\n",
    "data = [pd.read_csv(DATASETS_PATH + data_file, error_bad_lines=False) for data_file in data_files]\n",
    "data = pd.concat(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T16:52:35.048266Z",
     "start_time": "2021-06-26T16:52:35.043194Z"
    }
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T16:52:35.210039Z",
     "start_time": "2021-06-26T16:52:35.051018Z"
    }
   },
   "outputs": [],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T16:52:35.217164Z",
     "start_time": "2021-06-26T16:52:35.212054Z"
    }
   },
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T16:52:35.237698Z",
     "start_time": "2021-06-26T16:52:35.219022Z"
    }
   },
   "outputs": [],
   "source": [
    "data[\"Zone\"] = data[\"Block\"].apply(lambda x: x.split(\" \")[1])\n",
    "data[\"Address\"] = data[\"Block\"].apply(lambda x: \" \".join(x.split(\" \")[2:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T16:52:53.445115Z",
     "start_time": "2021-06-26T16:52:53.442627Z"
    }
   },
   "outputs": [],
   "source": [
    "TIME_COLUMN = \"Year\"\n",
    "TARGET = \"Arrest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T16:52:53.450958Z",
     "start_time": "2021-06-26T16:52:53.448743Z"
    }
   },
   "outputs": [],
   "source": [
    "columns_to_label_encode = [\"Primary Type\", \n",
    "                           \"Description\",\n",
    "                           \"Location Description\",\n",
    "                           \"FBI Code\",\n",
    "                           \"Zone\",\n",
    "                           \"Address\",\n",
    "                           \"Domestic\",\n",
    "                           TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T16:52:53.859050Z",
     "start_time": "2021-06-26T16:52:53.453922Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder_mappings = {}\n",
    "le = LabelEncoder()\n",
    "for column in columns_to_label_encode:\n",
    "    print(column)\n",
    "    data[column].fillna(\"None\", inplace=True)\n",
    "    data[column] = le.fit_transform(data[[column]])\n",
    "    encoder_mappings[column] = {i: le.__dict__[\"classes_\"][i] for i in range(len(le.__dict__[\"classes_\"]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"Primary Type\", \n",
    "            \"Description\",\n",
    "            \"Location Description\",\n",
    "            \"FBI Code\",\n",
    "            \"Zone\",\n",
    "            \"Address\",\n",
    "            \"Latitude\",\n",
    "            \"Longitude\",\n",
    "            \"Beat\",\n",
    "            \"District\",\n",
    "            \"Ward\",\n",
    "            \"Community Area\",\n",
    "            \"Domestic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T16:52:53.863731Z",
     "start_time": "2021-06-26T16:52:53.860886Z"
    }
   },
   "outputs": [],
   "source": [
    "numerical_features = [f for f in features if f not in columns_to_label_encode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T16:53:02.569762Z",
     "start_time": "2021-06-26T16:52:53.910132Z"
    }
   },
   "outputs": [],
   "source": [
    "data[\"Year\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T16:53:02.576056Z",
     "start_time": "2021-06-26T16:53:02.571026Z"
    }
   },
   "outputs": [],
   "source": [
    "data[\"year-month\"] = pd.to_datetime(data[\"Date\"]).apply(lambda x: str(x.year) + \"-\" + str(x.month).zfill(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T16:53:02.581383Z",
     "start_time": "2021-06-26T16:53:02.577819Z"
    }
   },
   "outputs": [],
   "source": [
    "data[\"Year\"] = data[\"Year\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T16:53:02.586682Z",
     "start_time": "2021-06-26T16:53:02.583014Z"
    }
   },
   "outputs": [],
   "source": [
    "data[\"Year\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Latitude\"] = data[\"Latitude\"].fillna(-1).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T16:53:02.591068Z",
     "start_time": "2021-06-26T16:53:02.588456Z"
    }
   },
   "outputs": [],
   "source": [
    "training_end_year = 2010\n",
    "holdout_end_year = 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T16:53:02.655738Z",
     "start_time": "2021-06-26T16:53:02.592800Z"
    }
   },
   "outputs": [],
   "source": [
    "in_time = data[data[\"Year\"] <= training_end_year]\n",
    "out_of_time = data[data[\"Year\"] > training_end_year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T16:53:02.688535Z",
     "start_time": "2021-06-26T16:53:02.657523Z"
    }
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(in_time, \n",
    "                               test_size=0.2,\n",
    "                               random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T16:53:02.694026Z",
     "start_time": "2021-06-26T16:53:02.690250Z"
    }
   },
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T16:53:02.700521Z",
     "start_time": "2021-06-26T16:53:02.696151Z"
    }
   },
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T16:53:02.706978Z",
     "start_time": "2021-06-26T16:53:02.702920Z"
    }
   },
   "outputs": [],
   "source": [
    "out_of_time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T16:53:02.779975Z",
     "start_time": "2021-06-26T16:53:02.715762Z"
    }
   },
   "outputs": [],
   "source": [
    "median_input = train.median()\n",
    "train.fillna(median_input, inplace=True)\n",
    "test.fillna(median_input, inplace=True)\n",
    "out_of_time.fillna(median_input, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the support in the different environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T16:53:02.861409Z",
     "start_time": "2021-06-26T16:53:02.783659Z"
    }
   },
   "outputs": [],
   "source": [
    "check_categoricals_match(train, columns_to_label_encode, \"Year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T16:53:02.881251Z",
     "start_time": "2021-06-26T16:53:02.863347Z"
    }
   },
   "outputs": [],
   "source": [
    "check_numerical_match(train, numerical_features, TIME_COLUMN, verbose=True, n_q=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T16:53:04.332770Z",
     "start_time": "2021-06-26T16:53:02.883712Z"
    }
   },
   "outputs": [],
   "source": [
    "from pycaret.classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T16:56:17.349726Z",
     "start_time": "2021-06-26T16:53:04.334088Z"
    }
   },
   "outputs": [],
   "source": [
    "clf1 = setup(train[features + [TARGET]], \n",
    "             target=TARGET,\n",
    "             session_id=2, \n",
    "             log_experiment=False, \n",
    "             experiment_name=\"{}\".format(PREFIX),\n",
    "             silent=True)\n",
    "\n",
    "rf = create_model('rf')\n",
    "tuned_rf = tune_model(rf,\n",
    "                     optimize=\"AUC\",\n",
    "                     fold=5,\n",
    "                     n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T16:56:17.357530Z",
     "start_time": "2021-06-26T16:56:17.352011Z"
    }
   },
   "outputs": [],
   "source": [
    "tuned_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T16:56:19.998278Z",
     "start_time": "2021-06-26T16:56:17.360101Z"
    }
   },
   "outputs": [],
   "source": [
    "benchmark_model = tuned_rf\n",
    "benchmark_model.fit(train[features], train[TARGET])\n",
    "\n",
    "train[\"benchmark_prediction_opt\"] = benchmark_model.predict_proba(train[features])[:, 1]\n",
    "test[\"benchmark_prediction_opt\"] = benchmark_model.predict_proba(test[features])[:, 1]\n",
    "out_of_time[\"benchmark_prediction_opt\"] = benchmark_model.predict_proba(out_of_time[features])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T16:56:20.057290Z",
     "start_time": "2021-06-26T16:56:20.000457Z"
    }
   },
   "outputs": [],
   "source": [
    "print(roc_auc_score(train[TARGET], train[\"benchmark_prediction_opt\"]))\n",
    "print(roc_auc_score(test[TARGET], test[\"benchmark_prediction_opt\"]))\n",
    "print(roc_auc_score(out_of_time[TARGET], out_of_time[\"benchmark_prediction_opt\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T16:56:28.716799Z",
     "start_time": "2021-06-26T16:56:20.059182Z"
    }
   },
   "outputs": [],
   "source": [
    "benchmark_model = RandomForestClassifier(n_estimators=250, max_depth=8)\n",
    "benchmark_model.fit(train[features], train[TARGET])\n",
    "\n",
    "train[\"benchmark_prediction\"] = benchmark_model.predict_proba(train[features])[:, 1]\n",
    "test[\"benchmark_prediction\"] = benchmark_model.predict_proba(test[features])[:, 1]\n",
    "out_of_time[\"benchmark_prediction\"] = benchmark_model.predict_proba(out_of_time[features])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T16:56:28.766515Z",
     "start_time": "2021-06-26T16:56:28.718220Z"
    }
   },
   "outputs": [],
   "source": [
    "print(roc_auc_score(train[TARGET], train[\"benchmark_prediction\"]))\n",
    "print(roc_auc_score(test[TARGET], test[\"benchmark_prediction\"]))\n",
    "print(roc_auc_score(out_of_time[TARGET], out_of_time[\"benchmark_prediction\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchmark_importances = benchmark_model.feature_importances_\n",
    "# benchmark_importances = pd.Series(benchmark_importances, index=features)\n",
    "# benchmark_importances.rename(\"RF\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = reverse_learning_curve(train, out_of_time, tuned_rf, features, TARGET, TIME_COLUMN, roc_auc_score, n_rounds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_importances = results[\"feature_importance\"][-1].copy(deep=True)\n",
    "benchmark_importances.rename(\"RF\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_by_reverse_segment_benchmark = plot_feature_migration_from_learning_curve_results(results, features, \n",
    "                                                                                             save_as=\"../images/{}_benchmark_importance_migration_learning_curve.eps\".format(PREFIX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "blues = plt.get_cmap(\"Blues\")\n",
    "gradient = np.linspace(.2, 0.8, len(results[\"holdout_performance\"]))\n",
    "\n",
    "for i, r in enumerate(results[\"holdout_performance_by_period\"]):\n",
    "    r.plot(label=results[\"last_period_included\"][i], color=blues(gradient[i]))\n",
    "\n",
    "ax.xaxis.set_tick_params(labelsize=12)\n",
    "ax.yaxis.set_tick_params(labelsize=12)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), fontsize=12, title=\"Oldest time period included in train\")\n",
    "plt.ylabel(\"AUC\", fontsize=15)\n",
    "plt.xlabel(\"Year\", fontsize=15)\n",
    "\n",
    "plt.savefig(\"../images/{}_perf_by_period_reverse_learning_curve_benchmark.eps\".format(PREFIX), format=\"eps\", bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenger model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T16:56:28.771371Z",
     "start_time": "2021-06-26T16:56:28.768379Z"
    }
   },
   "outputs": [],
   "source": [
    "train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T16:56:28.789493Z",
     "start_time": "2021-06-26T16:56:28.773208Z"
    }
   },
   "outputs": [],
   "source": [
    "train[features + [TIME_COLUMN]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T16:56:28.796459Z",
     "start_time": "2021-06-26T16:56:28.791288Z"
    }
   },
   "outputs": [],
   "source": [
    "train[\"Year\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHALLENGER_MAX_DEPTH = 9\n",
    "CHALLENGER_N_ESTIMATORS = 80\n",
    "CHALLENGER_MIN_SAMPLES_BY_PERIODS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenger_model_max = TimeForestClassifier(time_column=TIME_COLUMN,\n",
    "                                        n_estimators=CHALLENGER_N_ESTIMATORS,\n",
    "                                        min_sample_periods=CHALLENGER_MIN_SAMPLES_BY_PERIODS,\n",
    "                                        max_depth=CHALLENGER_MAX_DEPTH,\n",
    "                                        period_criterion='max',\n",
    "                                        multi=True)\n",
    "\n",
    "challenger_model_max.fit(train[features + [TIME_COLUMN]], train[TARGET].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"challenger_prediction_max\"] = challenger_model_max.predict_proba(train[features])[:, 1]\n",
    "test[\"challenger_prediction_max\"] = challenger_model_max.predict_proba(test[features])[:, 1]\n",
    "out_of_time[\"challenger_prediction_max\"] = challenger_model_max.predict_proba(out_of_time[features])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(roc_auc_score(train[TARGET], train[\"challenger_prediction_max\"]))\n",
    "print(roc_auc_score(test[TARGET], test[\"challenger_prediction_max\"]))\n",
    "print(roc_auc_score(out_of_time[TARGET], out_of_time[\"challenger_prediction_max\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenger_model_max.feature_importance()\n",
    "\n",
    "challenger_model_max_importances = challenger_model_max.feature_importance()\n",
    "challenger_model_max_importances.rename(\"TRF Max\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T18:23:39.252988Z",
     "start_time": "2021-06-26T16:56:28.798016Z"
    }
   },
   "outputs": [],
   "source": [
    "challenger_model = TimeForestClassifier(time_column=TIME_COLUMN,\n",
    "                                        n_estimators=CHALLENGER_N_ESTIMATORS,\n",
    "                                        min_sample_periods=CHALLENGER_MIN_SAMPLES_BY_PERIODS,\n",
    "                                        max_depth=CHALLENGER_MAX_DEPTH,\n",
    "                                        multi=True)\n",
    "challenger_model.fit(train[features + [TIME_COLUMN]], train[TARGET].values)\n",
    "\n",
    "train[\"challenger_prediction\"] = challenger_model.predict_proba(train[features])[:, 1]\n",
    "test[\"challenger_prediction\"] = challenger_model.predict_proba(test[features])[:, 1]\n",
    "out_of_time[\"challenger_prediction\"] = challenger_model.predict_proba(out_of_time[features])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T18:23:39.311366Z",
     "start_time": "2021-06-26T18:23:39.254800Z"
    }
   },
   "outputs": [],
   "source": [
    "print(roc_auc_score(train[TARGET], train[\"challenger_prediction\"]))\n",
    "print(roc_auc_score(test[TARGET], test[\"challenger_prediction\"]))\n",
    "print(roc_auc_score(out_of_time[TARGET], out_of_time[\"challenger_prediction\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance migration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenger_model = TimeForestClassifier(time_column=TIME_COLUMN,\n",
    "                                        n_estimators=CHALLENGER_N_ESTIMATORS,\n",
    "                                        min_sample_periods=CHALLENGER_MIN_SAMPLES_BY_PERIODS,\n",
    "                                        max_depth=CHALLENGER_MAX_DEPTH,\n",
    "                                        multi=True)\n",
    "\n",
    "results_trt = reverse_learning_curve(train, out_of_time, challenger_model, features, TARGET, TIME_COLUMN, roc_auc_score, n_rounds=5, trt_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenger_model_importances = results_trt[\"feature_importance\"][-1].copy(deep=True)\n",
    "challenger_model_importances.rename(\"TRF\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models_importance = pd.DataFrame(index=features)\n",
    "all_models_importance = all_models_importance.merge(benchmark_importances, how=\"left\", left_index=True, \n",
    "                            right_index=True)\n",
    "all_models_importance = all_models_importance.merge(challenger_model_importances, how=\"left\", left_index=True, \n",
    "                            right_index=True)\n",
    "all_models_importance = all_models_importance.merge(challenger_model_max_importances, how=\"left\", left_index=True, \n",
    "                            right_index=True)\n",
    "\n",
    "all_models_importance.fillna(0, inplace=True)\n",
    "all_models_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_shap_difference(all_models_importance[[\"RF\", \"TRF\"]], title=\"\", save_as=\"../images/{}_importance_migration.eps\".format(PREFIX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_shap_difference(all_models_importance, title=\"\", save_as=\"../images/{}_importance_migration_trf_max.eps\".format(PREFIX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_by_reverse_segment_challenger = plot_feature_migration_from_learning_curve_results(results_trt, features, \n",
    "                                                                                             save_as=\"../images/{}_challenger_importance_migration_learning_curve.eps\".format(PREFIX))\n",
    "importance_by_reverse_segment_challenger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "greens = plt.get_cmap(\"Greens\")\n",
    "gradient = np.linspace(.2, 0.8, len(results_trt[\"holdout_performance\"]))\n",
    "\n",
    "for i, r in enumerate(results_trt[\"holdout_performance_by_period\"]):\n",
    "    r.plot(label=results_trt[\"last_period_included\"][i], color=greens(gradient[i]))\n",
    "\n",
    "ax.xaxis.set_tick_params(labelsize=12)\n",
    "ax.yaxis.set_tick_params(labelsize=12)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), fontsize=12, title=\"Oldest time period included in train\")\n",
    "plt.ylabel(\"AUC\", fontsize=15)\n",
    "plt.xlabel(\"Year\", fontsize=15)\n",
    "\n",
    "plt.savefig(\"../images/{}_perf_by_period_reverse_learning_curve_challenger.eps\".format(PREFIX), format=\"eps\", bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.plot([str(i) for i in results[\"sample_size\"]], results[\"holdout_performance\"], label=\"RF\")\n",
    "plt.plot(results_trt[\"holdout_performance\"], label=\"TRF\", linestyle=\"dashed\", color=\"green\")\n",
    "ax.xaxis.set_tick_params(labelsize=12)\n",
    "ax.yaxis.set_tick_params(labelsize=12)\n",
    "plt.legend(fontsize=15, bbox_to_anchor=(1.0, 1.0))\n",
    "plt.ylabel(\"AUC in the holdout\", fontsize=15)\n",
    "plt.xlabel(\"Sample size\", fontsize=15)\n",
    "plt.savefig(\"../images/{}_reverse_learning_curve_sample.eps\".format(PREFIX), format=\"eps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.plot([str(i) for i in results[\"last_period_included\"]], results[\"holdout_performance\"], label=\"RF\")\n",
    "plt.plot(results_trt[\"holdout_performance\"], label=\"TRF\", linestyle=\"dashed\", color=\"green\")\n",
    "ax.xaxis.set_tick_params(labelsize=12)\n",
    "ax.yaxis.set_tick_params(labelsize=12)\n",
    "plt.legend(fontsize=15, bbox_to_anchor=(1.0, 1.0))\n",
    "plt.ylabel(\"AUC in the holdout\", fontsize=15)\n",
    "plt.xlabel(\"Oldest time period included in the training\", fontsize=15)\n",
    "plt.savefig(\"../images/{}_reverse_learning_curve_segments.eps\".format(PREFIX), format=\"eps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "greens = plt.get_cmap(\"Greens\")\n",
    "gradient = np.linspace(.2, 0.8, len(results_trt[\"holdout_performance\"]))\n",
    "\n",
    "for i, r in enumerate(results_trt[\"holdout_performance_by_period\"]):\n",
    "    r.plot(label=results_trt[\"last_period_included\"][i], color=greens(gradient[i]))\n",
    "    \n",
    "for i, r in enumerate(results[\"holdout_performance_by_period\"]):\n",
    "    r.plot(label=results[\"last_period_included\"][i], color=blues(gradient[i]))\n",
    "\n",
    "ax.xaxis.set_tick_params(labelsize=12)\n",
    "ax.yaxis.set_tick_params(labelsize=12)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), fontsize=12, title=\"Oldest time period included in train\")\n",
    "plt.ylabel(\"AUC\", fontsize=15)\n",
    "plt.xlabel(\"Year\", fontsize=15)\n",
    "\n",
    "plt.savefig(\"../images/{}_perf_by_period_reverse_learning_curve_both.eps\".format(PREFIX), format=\"eps\", bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "pd.concat([test, out_of_time]).groupby(TIME_COLUMN).apply(lambda x: roc_auc_score(x[TARGET], x[\"challenger_prediction\"])).plot(label=\"Time Robust Forest\", \n",
    "                                                                                                      linestyle=\"dashed\",\n",
    "                                                                                                      color=\"green\", ax=ax)\n",
    "pd.concat([test, out_of_time]).groupby(TIME_COLUMN).apply(lambda x: roc_auc_score(x[TARGET], x[\"benchmark_prediction_opt\"])).plot(label=\"Random Forest\", ax=ax)\n",
    "\n",
    "ax.xaxis.set_tick_params(labelsize=12)\n",
    "ax.yaxis.set_tick_params(labelsize=12)\n",
    "\n",
    "xmin, xmax, ymin, ymax = plt.axis()\n",
    "plt.vlines(training_end_year + 1, ymin, ymax, linestyle=\"dotted\", color=\"red\", label=\"Holdout start\")\n",
    "plt.ylim([ymin, ymax])\n",
    "plt.legend(fontsize=15, bbox_to_anchor=(1.0, 1.0))\n",
    "plt.ylabel(\"AUC\", fontsize=15)\n",
    "plt.xlabel(\"Year\", fontsize=15)\n",
    "plt.savefig(\"../images/{}_test_holdout_auc_years.eps\".format(PREFIX), format=\"eps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (8, 6)\n",
    "fig, ax = plt.subplots()\n",
    "pd.concat([test, out_of_time]).groupby(TIME_COLUMN).apply(lambda x: roc_auc_score(x[TARGET], x[\"challenger_prediction\"])).plot(label=\"Time Robust Forest\", \n",
    "                                                                                                      linestyle=\"dashed\",\n",
    "                                                                                                      color=\"green\", ax=ax)\n",
    "pd.concat([test, out_of_time]).groupby(TIME_COLUMN).apply(lambda x: roc_auc_score(x[TARGET], x[\"benchmark_prediction_opt\"])).plot(label=\"Random Forest\", ax=ax)\n",
    "\n",
    "\n",
    "ax.xaxis.set_tick_params(labelsize=15)\n",
    "ax.yaxis.set_tick_params(labelsize=15)\n",
    "\n",
    "xmin, xmax, ymin, ymax = plt.axis()\n",
    "plt.vlines(training_end_year + 1, ymin, ymax, linestyle=\"dotted\", color=\"red\", label=\"Holdout start\")\n",
    "plt.ylim([ymin, ymax])\n",
    "plt.legend(fontsize=13, bbox_to_anchor=(0.42, 1.0))\n",
    "\n",
    "plt.ylabel(\"AUC\", fontsize=16)\n",
    "plt.xlabel(\"Year\", fontsize=16)\n",
    "plt.savefig(\"../images/{}_test_holdout_auc_years_square.eps\".format(PREFIX), format=\"eps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRF as feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T18:30:46.653572Z",
     "start_time": "2021-06-26T18:30:46.288845Z"
    }
   },
   "outputs": [],
   "source": [
    "challenger_model.feature_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T18:30:49.053954Z",
     "start_time": "2021-06-26T18:30:46.655784Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_features = [feature for feature in features if feature in challenger_model.feature_importance().index]\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(selected_features) == len(features):\n",
    "    selected_features = list(challenger_model.feature_importance().sort_values(ascending=False).index[:int(len(features)/2)+2].values)\n",
    "    \n",
    "selected_features    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T18:33:38.708090Z",
     "start_time": "2021-06-26T18:30:49.057135Z"
    }
   },
   "outputs": [],
   "source": [
    "clf1 = setup(train[selected_features + [TARGET]], \n",
    "             target=TARGET,\n",
    "             session_id=3, \n",
    "             log_experiment=False, \n",
    "             experiment_name=\"{}_fs\".format(PREFIX),\n",
    "             silent=True)\n",
    "\n",
    "rf = create_model('rf')\n",
    "tuned_rf = tune_model(rf,\n",
    "                     optimize=\"AUC\",\n",
    "                     fold=5,\n",
    "                     n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T18:33:38.716121Z",
     "start_time": "2021-06-26T18:33:38.711054Z"
    }
   },
   "outputs": [],
   "source": [
    "tuned_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T18:33:39.742023Z",
     "start_time": "2021-06-26T18:33:38.718506Z"
    }
   },
   "outputs": [],
   "source": [
    "benchmark_model = tuned_rf\n",
    "benchmark_model.fit(train[selected_features], train[TARGET])\n",
    "\n",
    "train[\"benchmark_prediction_opt_selected_features\"] = benchmark_model.predict_proba(train[selected_features])[:, 1]\n",
    "test[\"benchmark_prediction_opt_selected_features\"] = benchmark_model.predict_proba(test[selected_features])[:, 1]\n",
    "out_of_time[\"benchmark_prediction_opt_selected_features\"] = benchmark_model.predict_proba(out_of_time[selected_features])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T18:33:39.798579Z",
     "start_time": "2021-06-26T18:33:39.744812Z"
    }
   },
   "outputs": [],
   "source": [
    "print(roc_auc_score(train[TARGET], train[\"benchmark_prediction_opt_selected_features\"]))\n",
    "print(roc_auc_score(test[TARGET], test[\"benchmark_prediction_opt_selected_features\"]))\n",
    "print(roc_auc_score(out_of_time[TARGET], out_of_time[\"benchmark_prediction_opt_selected_features\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T18:33:40.395501Z",
     "start_time": "2021-06-26T18:33:39.801672Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "pd.concat([test, out_of_time]).groupby(TIME_COLUMN).apply(lambda x: roc_auc_score(x[TARGET], x[\"challenger_prediction\"])).plot(label=\"Time Robust Forest\", \n",
    "                                                                                                      linestyle=\"dashed\",\n",
    "                                                                                                      color=\"green\", ax=ax)\n",
    "pd.concat([test, out_of_time]).groupby(TIME_COLUMN).apply(lambda x: roc_auc_score(x[TARGET], x[\"benchmark_prediction_opt\"])).plot(label=\"Random Forest\", ax=ax)\n",
    "\n",
    "pd.concat([test, out_of_time]).groupby(TIME_COLUMN).apply(lambda x: roc_auc_score(x[TARGET], x[\"benchmark_prediction_opt_selected_features\"])).plot(label=\"Random Forest w/ TRF feature selection\", ax=ax)\n",
    "\n",
    "\n",
    "ax.xaxis.set_tick_params(labelsize=15)\n",
    "ax.yaxis.set_tick_params(labelsize=15)\n",
    "\n",
    "xmin, xmax, ymin, ymax = plt.axis()\n",
    "plt.vlines(training_end_year + 1, ymin, ymax, linestyle=\"dotted\", color=\"red\", label=\"Holdout start\")\n",
    "plt.ylim([ymin, ymax])\n",
    "plt.legend(fontsize=10, bbox_to_anchor=(0.52, 0.25))\n",
    "plt.ylabel(\"AUC\", fontsize=16)\n",
    "plt.xlabel(\"Year\", fontsize=16)\n",
    "plt.savefig(\"../images/{}_test_holdout_auc_years_square_fs.eps\".format(PREFIX), format=\"eps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygam import LinearGAM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib.collections import PolyCollection as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.distplot(out_of_time[\"challenger_prediction\"], label=\"TRF\")\n",
    "sns.distplot(out_of_time[\"benchmark_prediction_opt\"], label=\"RF\")\n",
    "\n",
    "ax.xaxis.set_tick_params(labelsize=12)\n",
    "ax.yaxis.set_tick_params(labelsize=12)\n",
    "\n",
    "plt.legend(fontsize=15, bbox_to_anchor=(1.0, 1.0))\n",
    "plt.ylabel(\"Density\", fontsize=15)\n",
    "plt.xlabel(\"Score\", fontsize=15)\n",
    "\n",
    "__file__ = \"../images/{}_trf_rf_score_distribution\".format(PREFIX)\n",
    "plt.savefig(__file__+\".jpg\", quality=95)\n",
    "for c in ax.findobj(p):\n",
    "    c.set_zorder(-1)\n",
    "    c.set_rasterized(True)\n",
    "ax.set_rasterization_zorder(0)\n",
    "\n",
    "ax.set_rasterized(True)\n",
    "plt.savefig(__file__+\".eps\")        \n",
    "\n",
    "plt.savefig(\"../images/{}_trf_rf_score_distribution.eps\".format(PREFIX), format=\"eps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "out_of_time[\"challenger_prediction_norm\"] = ss.fit_transform(out_of_time[[\"challenger_prediction\"]])\n",
    "out_of_time[\"benchmark_prediction_norm\"] = ss.fit_transform(out_of_time[[\"benchmark_prediction_opt\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(out_of_time[\"challenger_prediction_norm\"])\n",
    "sns.distplot(out_of_time[\"benchmark_prediction_norm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(out_of_time[features], \n",
    "                                                    out_of_time[[\"challenger_prediction\", \n",
    "                                                                 \"benchmark_prediction\"]],\n",
    "                                                    test_size=0.6,\n",
    "                                                    random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = [feature for feature in features if feature not in columns_to_label_encode]\n",
    "numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p99 = X_train[numerical_features].quantile(.99)\n",
    "p01 = X_train[numerical_features].quantile(.01)\n",
    "p005 = X_train.quantile(.005)\n",
    "\n",
    "X_train[numerical_features] = X_train[numerical_features].where(\n",
    "    X_train[numerical_features] < p99, other=p99, axis=1)\n",
    "X_test[numerical_features] = X_test[numerical_features].where(\n",
    "    X_test[numerical_features] < p99, other=p99, axis=1)\n",
    "\n",
    "X_train[numerical_features] = X_train[numerical_features].where(\n",
    "    X_train[numerical_features] > p01, other=p01, axis=1)\n",
    "X_test[numerical_features] = X_test[numerical_features].where(\n",
    "    X_test[numerical_features] > p01, other=p01, axis=1)\n",
    "\n",
    "X_train = X_train.fillna(p005)\n",
    "X_test = X_test.fillna(p005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = [\"numerical\" if feature not in columns_to_label_encode else \"categorical\" for feature in features]\n",
    "\n",
    "gam_challenger = LinearGAM(dtype=dtype).gridsearch(X_train[features].values, y_train[\"challenger_prediction\"].values)\n",
    "gam_benchmark = LinearGAM(dtype=dtype).gridsearch(X_train[features].values, y_train[\"benchmark_prediction\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = gam_challenger.predict(X_test[features])\n",
    "print(\"r2 test (challenger): %f\" %r2_score(y_test[\"challenger_prediction\"], pred_test))\n",
    "\n",
    "pred_test = gam_benchmark.predict(X_test[features])\n",
    "print(\"r2 test (benchmark): %f\" %r2_score(y_test[\"benchmark_prediction\"], pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, feat in enumerate(features):\n",
    "    if feat not in numerical_features:\n",
    "        continue\n",
    "    print(feat)\n",
    "    print(i)\n",
    "    XX = gam_challenger.generate_X_grid(i, n=X_test.shape[0])\n",
    "    ### Fix needed for this dataset\n",
    "    #XX[:, 5] = X_test.values[:, 5]\n",
    "    pdep, confi = gam_challenger.partial_dependence(i, X=XX, width=.95)\n",
    "    fig, ax = plt.subplots(figsize=(10, 6), dpi=150)\n",
    "\n",
    "    plt.plot(XX[:, i], pdep, c=\"green\", label=\"TRF\")\n",
    "    plt.plot(XX[:, i], confi, c='green', ls='--')\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.legend()\n",
    "\n",
    "    ### Benchmark\n",
    "    pdep, confi = gam_benchmark.partial_dependence(i, X=XX, width=.95)\n",
    "    plt.plot(XX[:, i], pdep, color=\"#4c72b0\", label=\"RF\")\n",
    "    plt.plot(XX[:, i], confi, c='#4c72b0', ls='--')\n",
    "    plt.ylabel(\"Score\", fontsize=15)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.xlabel(feat, fontsize=15)\n",
    "\n",
    "    ax.xaxis.set_tick_params(labelsize=12)\n",
    "    ax.yaxis.set_tick_params(labelsize=12)\n",
    "    xmin, xmax, ymin, ymax = plt.axis()\n",
    "    plt.ylim([ymin, ymax])\n",
    "    plt.legend(fontsize=15)\n",
    "    plt.savefig(\"../images/{}_feature_impact_{}.eps\".format(PREFIX, feat), format=\"eps\")\n",
    "\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, feat in enumerate(features):\n",
    "    if feat in columns_to_label_encode:\n",
    "        print(feat)\n",
    "        try:\n",
    "            mapping = encoder_mappings[feat]\n",
    "            max_cat = np.max(list(mapping.keys()))\n",
    "            if max_cat > 100:\n",
    "                continue\n",
    "            XX = np.copy(X_test)\n",
    "            XX[:, i] = np.random.randint(0, max_cat, size=X_test.shape[0])\n",
    "            pdep, confi = gam_challenger.partial_dependence(i, X=XX, width=.95)\n",
    "            fig, ax = plt.subplots(figsize=(10, 5), dpi=150)\n",
    "            data = pd.DataFrame(np.hstack([XX[:, i].reshape(-1, 1), pdep.reshape(-1, 1), confi]),\n",
    "                                columns=[feat, \"Mean Impact\", \"low\", \"high\"])\n",
    "            data[\"low\"] = np.abs(data[\"low\"] - data[\"Mean Impact\"])\n",
    "            data[\"high\"] = np.abs(data[\"high\"] - data[\"Mean Impact\"])\n",
    "            agg = data.groupby(feat).mean()\n",
    "\n",
    "            impact_plot = plt.bar([i for i in range(len(agg))],\n",
    "                                  agg[\"Mean Impact\"],\n",
    "                                  yerr=agg[[\"low\", \"high\"]].values.transpose(),\n",
    "                                  color=\"#9370DB\",\n",
    "                                  capsize=7)\n",
    "\n",
    "            plt.title(feat, fontsize=15)\n",
    "            plt.xticks([i for i in range(len(list(mapping.keys())))])\n",
    "            ax.set_xticklabels(list(mapping.values()), rotation=90)\n",
    "            plt.hlines(0.0, -1, max_cat, linestyles=\"dashed\")\n",
    "            plt.ylabel(\"Score\", fontsize=15)\n",
    "\n",
    "            ax.xaxis.set_tick_params(labelsize=12)\n",
    "            ax.yaxis.set_tick_params(labelsize=12)\n",
    "            xmin, xmax, ymin, ymax = plt.axis()\n",
    "            plt.ylim([ymin, ymax])\n",
    "            plt.legend(fontsize=15)\n",
    "            plt.savefig(\"../images/{}_feature_impact_cat_{}.eps\".format(PREFIX, feat), format=\"eps\")\n",
    "\n",
    "            plt.show()\n",
    "            plt.clf()\n",
    "        except:\n",
    "            print(\"No plot for {}\".format(feat))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, feat in enumerate(features):\n",
    "    if feat in columns_to_label_encode:\n",
    "        print(feat)\n",
    "        mapping = encoder_mappings[feat]\n",
    "        max_cat = np.max(list(mapping.keys()))\n",
    "        if max_cat > 100:\n",
    "            continue\n",
    "        XX = np.copy(X_test)\n",
    "        XX[:, i] = np.random.randint(0, max_cat, size=X_test.shape[0])\n",
    "        ### Challenger\n",
    "        pdep, confi = gam_challenger.partial_dependence(i, X=XX, width=.95)\n",
    "        fig, ax = plt.subplots(figsize=(10, 5), dpi=150)\n",
    "        data = pd.DataFrame(np.hstack([XX[:, i].reshape(-1, 1), pdep.reshape(-1, 1), confi]),\n",
    "                            columns=[feat, \"Mean Impact\", \"low\", \"high\"])\n",
    "        data[\"low\"] = np.abs(data[\"low\"] - data[\"Mean Impact\"])\n",
    "        data[\"high\"] = np.abs(data[\"high\"] - data[\"Mean Impact\"])\n",
    "        data[\"model\"] = \"TRF\"\n",
    "        agg = data.groupby(feat).mean()\n",
    "\n",
    "\n",
    "        ### Benchmark\n",
    "        pdep, confi = gam_benchmark.partial_dependence(i, X=XX, width=.95)\n",
    "        data_benchmark = pd.DataFrame(np.hstack([XX[:, i].reshape(-1, 1), pdep.reshape(-1, 1), confi]),\n",
    "                            columns=[feat, \"Mean Impact\", \"low\", \"high\"])\n",
    "        data_benchmark[\"low\"] = np.abs(data_benchmark[\"low\"] - data_benchmark[\"Mean Impact\"])\n",
    "        data_benchmark[\"high\"] = np.abs(data_benchmark[\"high\"] - data_benchmark[\"Mean Impact\"])\n",
    "        data_benchmark[\"model\"] = \"RF\"\n",
    "        \n",
    "        data = pd.concat([data, data_benchmark])\n",
    "        agg = data.groupby(feat).mean()\n",
    "        \n",
    "        sns.barplot(data=data, x=feat, y=\"Mean Impact\", hue=\"model\")\n",
    "\n",
    "\n",
    "        plt.xticks([i for i in range(len(list(mapping.keys())))])\n",
    "        ax.set_xticklabels(list(mapping.values()), rotation=90)\n",
    "        plt.hlines(0.0, -1, max_cat, linestyles=\"dashed\")\n",
    "        plt.ylabel(\"Score\", fontsize=15)\n",
    "        \n",
    "        ax.xaxis.set_tick_params(labelsize=12)\n",
    "        ax.yaxis.set_tick_params(labelsize=12)\n",
    "        xmin, xmax, ymin, ymax = plt.axis()\n",
    "        plt.ylim([ymin, ymax])\n",
    "        plt.legend(fontsize=15)\n",
    "        plt.xlabel(feat, fontsize=15)\n",
    "        plt.savefig(\"../images/{}_feature_impact_cat_comparison_{}.eps\".format(PREFIX, feat), format=\"eps\")\n",
    "        \n",
    "        plt.show()\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimum samples by period effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = TARGET\n",
    "min_sample_periods_values = [1, 5, 10, 20, 50, 100, 250, 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sample_knob = {}\n",
    "min_sample_knob[\"challenger\"] = {\"unseen_performance\": [], \"train_performance\": [],\n",
    "                                \"test_performance\": [], \"unseen_performance_by_period\": []}\n",
    "unseen_performance = []\n",
    "train_performance = []\n",
    "test_performance = []\n",
    "unseen_performance_by_period = []\n",
    "\n",
    "for min_sample_periods in min_sample_periods_values:\n",
    "    model_split_time = TimeForestClassifier(time_column=TIME_COLUMN,\n",
    "                                        n_estimators=CHALLENGER_N_ESTIMATORS,\n",
    "                                        min_sample_periods=min_sample_periods,\n",
    "                                        max_depth=CHALLENGER_MAX_DEPTH,\n",
    "                                        multi=True)\n",
    "    \n",
    "    model_split_time.fit(train[features + [TIME_COLUMN]], train[target])\n",
    "    out_of_time[\"time_split_prediction\"] = model_split_time.predict_proba(out_of_time[features])[:, 1]\n",
    "    \n",
    "    performance = metrics.roc_auc_score(out_of_time[target], out_of_time[\"time_split_prediction\"])\n",
    "    min_sample_knob[\"challenger\"][\"unseen_performance\"].append(performance)\n",
    "    min_sample_knob[\"challenger\"][\"unseen_performance_by_period\"].append(out_of_time.groupby(TIME_COLUMN).apply(lambda x: roc_auc_score(x[target], x[\"time_split_prediction\"])))\n",
    "\n",
    "    train[\"time_split_prediction\"] = model_split_time.predict(train[features])\n",
    "    min_sample_knob[\"challenger\"][\"train_performance\"].append(metrics.roc_auc_score(train[target], train[\"time_split_prediction\"]))\n",
    "    \n",
    "    test[\"time_split_prediction\"] = model_split_time.predict(test[features])\n",
    "    min_sample_knob[\"challenger\"][\"test_performance\"].append(metrics.roc_auc_score(test[target], test[\"time_split_prediction\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.plot(min_sample_periods_values, min_sample_knob[\"challenger\"][\"train_performance\"], label=\"Train\")\n",
    "plt.plot(min_sample_periods_values, min_sample_knob[\"challenger\"][\"test_performance\"], label=\"Test\", \n",
    "         color=\"magenta\",\n",
    "         linestyle=\"dotted\")\n",
    "plt.plot(min_sample_periods_values, min_sample_knob[\"challenger\"][\"unseen_performance\"], label=\"Holdout\", \n",
    "                                                         linestyle=\"dashed\",\n",
    "                                                         color=\"green\")\n",
    "\n",
    "#plt.title(\"Holdout AUC by minimum examples by period parameter\", fontsize=15)\n",
    "ax.xaxis.set_tick_params(labelsize=12)\n",
    "ax.yaxis.set_tick_params(labelsize=12)\n",
    "xmin, xmax, ymin, ymax = plt.axis()\n",
    "plt.ylim([ymin, ymax])\n",
    "plt.legend(fontsize=15)\n",
    "plt.ylabel(\"AUC\", fontsize=15)\n",
    "plt.xlabel(\"Minimum examples by period\", fontsize=15)\n",
    "plt.savefig(\"../images/{}_test_min_example_by_period_train_and_holdout_whole.eps\".format(PREFIX), format=\"eps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "greens = plt.get_cmap(\"Greens\")\n",
    "gradient = np.linspace(.1, 0.9, len(min_sample_periods_values))\n",
    "for i, experiment in enumerate(min_sample_knob[\"challenger\"][\"unseen_performance_by_period\"]):\n",
    "    experiment.plot(label=min_sample_periods_values[i], color=greens(gradient[i]))\n",
    "\n",
    "out_of_time.groupby(TIME_COLUMN).apply(lambda x: roc_auc_score(x[target], x[\"benchmark_prediction_opt\"])).plot(label=\"Optimal RF benchmark\", \n",
    "                                                                                                 color=\"red\", linestyle=\"dashed\", ax=ax)\n",
    "ax.xaxis.set_tick_params(labelsize=12)\n",
    "ax.yaxis.set_tick_params(labelsize=12)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), fontsize=12, title=\"Minimum examples by period\")\n",
    "plt.ylabel(\"AUC\", fontsize=15)\n",
    "plt.xlabel(\"Year\", fontsize=15)\n",
    "\n",
    "x_labels = np.sort(out_of_time[TIME_COLUMN].unique())\n",
    "plt.xticks(x_labels)\n",
    "\n",
    "plt.savefig(\"../images/{}_holdout_dif_min_samples.eps\".format(PREFIX), format=\"eps\", bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sample_knob[\"benchmark\"] = {\"unseen_performance\": [], \"train_performance\": [],\n",
    "                                \"test_performance\": [], \"unseen_performance_by_period\": []}\n",
    "\n",
    "training_segments = train[TIME_COLUMN].nunique()\n",
    "for min_sample_periods in min_sample_periods_values:\n",
    "\n",
    "    model = tuned_rf\n",
    "    model.set_params(min_samples_leaf=training_segments * min_sample_periods)\n",
    "    \n",
    "    \n",
    "    model.fit(train[features],\n",
    "              train[TARGET])\n",
    "     \n",
    "    out_of_time[\"time_split_prediction\"] = model.predict_proba(out_of_time[features])[:, 1]\n",
    "    \n",
    "    performance = metrics.roc_auc_score(out_of_time[target], out_of_time[\"time_split_prediction\"])\n",
    "    min_sample_knob[\"benchmark\"][\"unseen_performance\"].append(performance)\n",
    "    min_sample_knob[\"benchmark\"][\"unseen_performance_by_period\"].append(out_of_time.groupby(TIME_COLUMN).apply(lambda x: roc_auc_score(x[target], x[\"time_split_prediction\"])))\n",
    "\n",
    "    train[\"time_split_prediction\"] = model.predict(train[features])\n",
    "    min_sample_knob[\"benchmark\"][\"train_performance\"].append(metrics.roc_auc_score(train[target], train[\"time_split_prediction\"]))\n",
    "    \n",
    "    test[\"time_split_prediction\"] = model.predict(test[features])\n",
    "    min_sample_knob[\"benchmark\"][\"test_performance\"].append(metrics.roc_auc_score(test[target], test[\"time_split_prediction\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "blues = plt.get_cmap(\"Blues\")\n",
    "for i, experiment in enumerate(min_sample_knob[\"benchmark\"][\"unseen_performance_by_period\"]):\n",
    "    experiment.plot(label=min_sample_periods_values[i], color=blues(gradient[i]))\n",
    "\n",
    "out_of_time.groupby(TIME_COLUMN).apply(lambda x: roc_auc_score(x[target], x[\"benchmark_prediction_opt\"])).plot(label=\"Optimal RF benchmark\", \n",
    "                                                                                                 color=\"red\", linestyle=\"dashed\", ax=ax)\n",
    "\n",
    "ax.xaxis.set_tick_params(labelsize=12)\n",
    "ax.yaxis.set_tick_params(labelsize=12)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), fontsize=12, title=\"Minimum examples by period\")\n",
    "plt.ylabel(\"AUC\", fontsize=15)\n",
    "plt.xlabel(\"Year\", fontsize=15)\n",
    "\n",
    "x_labels = np.sort(out_of_time[TIME_COLUMN].unique())\n",
    "plt.xticks(x_labels)\n",
    "\n",
    "plt.savefig(\"../images/{}_holdout_dif_min_samples_benchmark.eps\".format(PREFIX), format=\"eps\", bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for i, experiment in enumerate(min_sample_knob[\"challenger\"][\"unseen_performance_by_period\"]):\n",
    "    experiment.plot(label=min_sample_periods_values[i], color=greens(gradient[i]))\n",
    "    \n",
    "for i, experiment in enumerate(min_sample_knob[\"benchmark\"][\"unseen_performance_by_period\"]):\n",
    "    experiment.plot(label=min_sample_periods_values[i], color=blues(gradient[i]))    \n",
    "\n",
    "ax.xaxis.set_tick_params(labelsize=12)\n",
    "ax.yaxis.set_tick_params(labelsize=12)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), fontsize=12, title=\"Minimum examples by period\")\n",
    "plt.ylabel(\"AUC\", fontsize=15)\n",
    "plt.xlabel(\"Year\", fontsize=15)\n",
    "\n",
    "x_labels = np.sort(out_of_time[TIME_COLUMN].unique())\n",
    "plt.xticks(x_labels)\n",
    "\n",
    "plt.savefig(\"../images/{}_holdout_dif_min_samples_benchmark_challenger.eps\".format(PREFIX), format=\"eps\", bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.plot(min_sample_periods_values, min_sample_knob[\"challenger\"][\"train_performance\"], label=\"TRF Train\",\n",
    "        color=\"#4c72b0\", linestyle=\"dashed\")\n",
    "plt.plot(min_sample_periods_values, min_sample_knob[\"challenger\"][\"test_performance\"], label=\"TRF Test\", \n",
    "         color=\"magenta\",\n",
    "         linestyle=\"dashed\")\n",
    "plt.plot(min_sample_periods_values, min_sample_knob[\"challenger\"][\"unseen_performance\"], label=\"TRF Holdout\", \n",
    "                                                         linestyle=\"dashed\",\n",
    "                                                         color=\"green\")\n",
    "\n",
    "plt.plot(min_sample_periods_values, min_sample_knob[\"benchmark\"][\"train_performance\"], label=\"RF Train\",\n",
    "        color=\"#4c72b0\")\n",
    "plt.plot(min_sample_periods_values, min_sample_knob[\"benchmark\"][\"test_performance\"], label=\"RF Test\", \n",
    "         color=\"magenta\")\n",
    "plt.plot(min_sample_periods_values, min_sample_knob[\"benchmark\"][\"unseen_performance\"], label=\"RF Holdout\", \n",
    "                                                         color=\"green\")\n",
    "\n",
    "#plt.title(\"Holdout AUC by minimum examples by period parameter\", fontsize=15)\n",
    "ax.xaxis.set_tick_params(labelsize=12)\n",
    "ax.yaxis.set_tick_params(labelsize=12)\n",
    "xmin, xmax, ymin, ymax = plt.axis()\n",
    "plt.ylim([ymin, ymax])\n",
    "plt.legend(fontsize=15)\n",
    "plt.ylabel(\"AUC\", fontsize=15)\n",
    "plt.xlabel(\"Minimum examples by period\", fontsize=15)\n",
    "plt.savefig(\"../images/{}_test_min_example_by_period_train_and_holdout_whole_bench_challenger.eps\".format(PREFIX), format=\"eps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "plt.plot(min_sample_periods_values, min_sample_knob[\"challenger\"][\"unseen_performance\"], label=\"TRF Holdout\", \n",
    "                                                         linestyle=\"dashed\",\n",
    "                                                         color=\"green\")\n",
    "\n",
    "plt.plot(min_sample_periods_values, min_sample_knob[\"benchmark\"][\"unseen_performance\"], label=\"RF Holdout\", \n",
    "                                                         color=\"green\")\n",
    "\n",
    "#plt.title(\"Holdout AUC by minimum examples by period parameter\", fontsize=15)\n",
    "ax.xaxis.set_tick_params(labelsize=12)\n",
    "ax.yaxis.set_tick_params(labelsize=12)\n",
    "xmin, xmax, ymin, ymax = plt.axis()\n",
    "plt.ylim([ymin, ymax])\n",
    "plt.legend(fontsize=15)\n",
    "plt.ylabel(\"AUC\", fontsize=15)\n",
    "plt.xlabel(\"Minimum examples by period\", fontsize=15)\n",
    "plt.savefig(\"../images/{}_holdout_min_example_by_period_train_and_holdout_whole_bench_challenger.eps\".format(PREFIX), format=\"eps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T22:07:53.853460Z",
     "start_time": "2021-04-02T22:07:51.540803Z"
    }
   },
   "outputs": [],
   "source": [
    "train[\"domain\"] = 1\n",
    "test[\"domain\"] = 1\n",
    "out_of_time[\"domain\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T22:08:07.073605Z",
     "start_time": "2021-04-02T22:07:59.614541Z"
    }
   },
   "outputs": [],
   "source": [
    "domain_data = pd.concat([train, test, out_of_time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T22:08:24.870133Z",
     "start_time": "2021-04-02T22:08:15.972350Z"
    }
   },
   "outputs": [],
   "source": [
    "train_domain, test_domain = train_test_split(domain_data, \n",
    "                               test_size=0.2,\n",
    "                               random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T22:37:20.824417Z",
     "start_time": "2021-04-02T22:09:11.137931Z"
    }
   },
   "outputs": [],
   "source": [
    "clf2 = setup(train_domain[features + [\"domain\"]], target=\"domain\",\n",
    "             session_id=124, \n",
    "             log_experiment=False, \n",
    "             experiment_name=\"{}_domain\".format(PREFIX),\n",
    "             silent=True)\n",
    "\n",
    "rf = create_model('rf')\n",
    "tuned_domain_rf = tune_model(rf,\n",
    "                             optimize=\"AUC\",\n",
    "                             fold=5,\n",
    "                             n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T22:37:20.843589Z",
     "start_time": "2021-04-02T22:37:20.836135Z"
    }
   },
   "outputs": [],
   "source": [
    "domain_model = tuned_domain_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T22:38:45.077018Z",
     "start_time": "2021-04-02T22:37:20.855449Z"
    }
   },
   "outputs": [],
   "source": [
    "domain_model.fit(train_domain[features], train_domain[\"domain\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T22:38:45.314167Z",
     "start_time": "2021-04-02T22:38:45.082144Z"
    }
   },
   "outputs": [],
   "source": [
    "test_domain[\"pred_domain\"] = domain_model.predict_proba(test_domain[features])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-02T22:38:45.346608Z",
     "start_time": "2021-04-02T22:38:45.318204Z"
    }
   },
   "outputs": [],
   "source": [
    "roc_auc_score(test_domain[\"domain\"], test_domain[\"pred_domain\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other optimization design for the RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_time_segment_in_train = np.max(in_time[TIME_COLUMN].unique())\n",
    "last_time_segment_in_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posfix = str(last_time_segment_in_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = in_time[in_time[\"Year\"] < last_time_segment_in_train]\n",
    "new_validation = in_time[in_time[\"Year\"] == last_time_segment_in_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = setup(new_train[features + [TARGET]], target=TARGET,\n",
    "             test_data=new_validation,\n",
    "             session_id=44,\n",
    "             log_experiment=False,\n",
    "             experiment_name=\"{}_opt1\".format(PREFIX),\n",
    "             silent=True)\n",
    "\n",
    "rf = create_model('rf')\n",
    "tuned_rf = tune_model(rf,\n",
    "                     optimize=\"AUC\",\n",
    "                     n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_model = tuned_rf\n",
    "benchmark_model.fit(train[features], train[TARGET])\n",
    "\n",
    "train[\"benchmark_prediction_opt_{}\".format(posfix)] = benchmark_model.predict_proba(train[features])[:, 1]\n",
    "test[\"benchmark_prediction_opt_{}\".format(posfix)] = benchmark_model.predict_proba(test[features])[:, 1]\n",
    "out_of_time[\"benchmark_prediction_opt_{}\".format(posfix)] = benchmark_model.predict_proba(out_of_time[features])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_validation, add_to_train = train_test_split(new_validation, test_size=0.5)\n",
    "\n",
    "new_train = pd.concat([new_train, add_to_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = setup(new_train[features + [TARGET]], target=TARGET,\n",
    "             test_data=new_validation,\n",
    "             session_id=22,\n",
    "             log_experiment=False,\n",
    "             experiment_name=\"{}_opt2\".format(PREFIX),\n",
    "             silent=True)\n",
    "\n",
    "rf = create_model('rf')\n",
    "tuned_rf = tune_model(rf,\n",
    "                     optimize=\"AUC\",\n",
    "                     n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_model = tuned_rf\n",
    "benchmark_model.fit(train[features], train[TARGET])\n",
    "\n",
    "train[\"benchmark_prediction_opt_half_{}\".format(posfix)] = benchmark_model.predict_proba(train[features])[:, 1]\n",
    "test[\"benchmark_prediction_opt_half_{}\".format(posfix)] = benchmark_model.predict_proba(test[features])[:, 1]\n",
    "out_of_time[\"benchmark_prediction_opt_half_{}\".format(posfix)] = benchmark_model.predict_proba(out_of_time[features])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "pd.concat([test, out_of_time]).groupby(TIME_COLUMN).apply(lambda x: roc_auc_score(x[TARGET], x[\"challenger_prediction\"])).plot(label=\"Time Robust Forest\", \n",
    "                                                                                                      linestyle=\"dashed\",\n",
    "                                                                                                      color=\"green\", ax=ax)\n",
    "\n",
    "pd.concat([test, out_of_time]).groupby(TIME_COLUMN).apply(lambda x: roc_auc_score(x[TARGET], x[\"benchmark_prediction_opt_half_{}\".format(posfix)])).plot(label=\"RF: Half {} in validation\".format(posfix), \n",
    "                                                                                                      #linestyle=\"dashed\",\n",
    "                                                                                                      color=\"purple\", ax=ax)\n",
    "pd.concat([test, out_of_time]).groupby(TIME_COLUMN).apply(lambda x: roc_auc_score(x[TARGET], x[\"benchmark_prediction_opt\"])).plot(label=\"RF: K-fold in the in-time\", ax=ax)\n",
    "pd.concat([test, out_of_time]).groupby(TIME_COLUMN).apply(lambda x: roc_auc_score(x[TARGET], x[\"benchmark_prediction_opt_{}\".format(posfix)])).plot(label=\"RF: Full {} in validation\".format(posfix), ax=ax)\n",
    "\n",
    "ax.xaxis.set_tick_params(labelsize=12)\n",
    "ax.yaxis.set_tick_params(labelsize=12)\n",
    "\n",
    "xmin, xmax, ymin, ymax = plt.axis()\n",
    "plt.vlines(training_end_year + 1, ymin, ymax, linestyle=\"dotted\", color=\"red\", label=\"Holdout start\")\n",
    "plt.ylim([ymin, ymax])\n",
    "plt.legend(fontsize=15, bbox_to_anchor=(1.0, 1.0))\n",
    "plt.ylabel(\"AUC\", fontsize=15)\n",
    "plt.xlabel(\"Year\", fontsize=15)\n",
    "plt.savefig(\"../images/{}_performance_proof.eps\".format(PREFIX), format=\"eps\", bbox_inches = \"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:.conda-msc]",
   "language": "python",
   "name": "conda-env-.conda-msc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Index",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
